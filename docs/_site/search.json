[
  {
    "objectID": "isochrones.html",
    "href": "isochrones.html",
    "title": "Isochrones calculator",
    "section": "",
    "text": "In geospatial analysis, one of the most important issues is identifying objects of interest that are within range of a given point. Think of all the cell phones that can be reached by an antenna, all the medical centers around a point in the city, and all the competitors near a store. For most of these problems, the most immediate solution is to define the range from a point in terms of distance. It is usually assumed to be Euclidean, but care must be taken because in geospatial analysis we work with projections.\nEven ignoring the caveats regarding distances and projections, the problem lies in the fact that the space being analyzed is not uniform: nature presents geographical features, societies carry out infrastructure projects that modify the distribution of spaces, and cities and living spaces are irregular.\nIn addition, when we carry out reach exercises, time is a constraint. It is not the same to say that there are five health centers within a five-kilometer radius as it is to say that they can be reached in less than T minutes. Thus, we can define the isochrone as follows:\n\nDef. An isochrone \\(I(x,t,Tt,Ht) \\in \\mathbb{R}^2\\) is the area or envelope of the set of routes that can be reached from point \\(x\\) in less than \\(t\\) minutes (or any unit of time measurement) for a type of transport \\(Tt\\) within a defined time frame \\(Ht\\).\n\nAlthough, in general, due to computational cost or lack of information, fixed conditions \\(T_t\\) and \\(H_t\\) are assumed, assumptions must always be specified.\nBelow is an example of a range radius for a 15-minute drive isochrone in Mexico City (average, OSM API, very optimistic arrivals!).\n\n\n\nIsochrones\n\n\nThis irregularity is what makes it necessary to take isochrones into account when studying range from a fixed point.\nThere are many complexities involved in dealing with isochrones, some of which are:\n- Heavy dependence on transportation vehicles.\n- The time of day when the journey is made. \n- Infrastructure and sensitivity to events (accidents).\n- Route adaptability and travel efficiency.\nHowever, their wide range of applications and importance in industry and research make it worthwhile to find algorithms and processes to estimate isochrones more accurately."
  },
  {
    "objectID": "isochrones.html#simulation-assumptions",
    "href": "isochrones.html#simulation-assumptions",
    "title": "Isochrones calculator",
    "section": "Simulation assumptions",
    "text": "Simulation assumptions\nIn addition to assumptions about people’s walking speed, in order to perform a more realistic simulation, the algorithm includes waiting and “traffic” parameters. In other words, let’s look at the following diagram:\n\n\n\nStreet crossing diagram\n\n\nWe assume that if a path is passable on foot, it is also passable by bicycle.\nWe also assume that streets are two-way for pedestrians and bicycles.\nAs we can see, even when walking, especially in an urban area, we are forced to wait for the traffic light to change. Even on pedestrian-only streets, the presence of other people forces us to take these waiting times into account. On the one hand, there is the probability of encountering a red light, and on the other, the waiting time in seconds until it changes. This generates more realistic data. We have included this logic in each of the nodes (corners)."
  },
  {
    "objectID": "isochrones_es.html",
    "href": "isochrones_es.html",
    "title": "Isochrones calculator",
    "section": "",
    "text": "En el análisis geoespacial, una de las cuestiones más importantes es identificar los objetos de interés que se encuentran dentro del alcance de un punto determinado. Piensa en todos los teléfonos móviles a los que llega una antena, en todos los centros médicos que hay alrededor de un punto de la ciudad y en todos los competidores cercanos a una tienda. Para la mayoría de estos problemas, la solución más inmediata consiste en definir el alcance desde un punto en términos de distancia. Normalmente se supone que es euclidiano, pero hay que tener cuidado porque en el análisis geoespacial trabajamos con proyecciones.\nIncluso ignorando las salvedades relativas a las distancias y las proyecciones, el problema radica en que el espacio que se analiza no es uniforme: la naturaleza presenta accidentes geográficos, las sociedades llevan a cabo proyectos de infraestructura que modifican la distribución de los espacios y las ciudades y los espacios habitacionales son irregulares.\nA esto hay que añadir que, cuando realizamos ejercicios de alcance, una restricción es el tiempo. No es lo mismo decir que hay cinco centros de salud en un radio de cinco kilómetros que decir que se pueden alcanzar en menos de T minutos. Así pues, podemos definir la isocrona de la siguiente forma:\n\nDef. Una isocrona \\(I(x,t,Tt,Ht) \\in \\mathbb{R}^2\\), es el área o envolvente del conjunto de rutas que se pueden alcanzar desde el punto \\(x\\) en menos de \\(t\\) minutos (o cualquier unidad de medida del tiempo) para un tipo de transporte \\(Tt\\) en un horario definifo \\(Ht\\)\n\nAunque, por lo general, debido al coste computacional o a la falta de información, se asumen condiciones \\(T_t\\) y \\(H_t\\) fijas, siempre se deben especificar los supuestos.\nA continuación se muestra un ejemplo de radio de alcance para una isocrona de 15 minutos en coche en la Ciudad de México (promedio, API de OSM, ¡llegadas muy optimistas!).\n\n\n\nIsócrona\n\n\nEsta irregularidad es la que hace necesario tener en cuenta las isocronas en el estudio del alcance desde un punto fijo.\nLas complejidades que surgen al lidiar con isocrónas son muchas, algunas de las cuales son:\n- Fuerte dependencia de los vehículos de transporte. \n- El momento del día en que se realiza el trayecto. \n- Infraestructura y sensibilidad a eventos (accidentes). \n- Adaptabilidad de la ruta y eficiencia de los recorridos. \nNo obstante, su gran cantidad de aplicaciones e importancia en la industria y la investigación hacen que valga la pena encontrar algoritmos y procesos para estimar isocronas de forma más precisa."
  },
  {
    "objectID": "isochrones_es.html#supuestos-de-simulación",
    "href": "isochrones_es.html#supuestos-de-simulación",
    "title": "Isochrones calculator",
    "section": "Supuestos de Simulación",
    "text": "Supuestos de Simulación\nAdemás de las suposiciones sobre la velocidad de marcha de las personas, con el fin de realizar una simulación más realista, el algoritmo incluye parámetros de espera y «tráfico». En otras palabras, veamos el siguiente esquema:\n\n\n\nDiagrama de cruce de calles\n\n\nSuponemos que si un camino es transitable a pie, también lo es para bicicletas.\nAsimismo, suponemos que las calles son de doble sentido para peatones y bicicletas.\nComo podemos ver, incluso cuando caminamos, especialmente en una zona urbana, nos vemos obligados a esperar a que cambie el semáforo. Incluso en las calles exclusivas para peatones, la presencia de otras personas nos obliga a tener en cuenta estos tiempos de espera. Por un lado, está la probabilidad de encontrarnos con un semáforo en rojo y, por otro, el tiempo de espera en segundos hasta que cambie. Esto genera datos más realistas. Hemos incluido esta lógica en cada uno de los nodos (esquinas)."
  },
  {
    "objectID": "data_hacks.html",
    "href": "data_hacks.html",
    "title": "Data Hacks",
    "section": "",
    "text": "This page provides a series of APIs, web links and code snippets that I have used for geospatial analysis, enabling the retrieval of data from public sources, government institutions, data science repositories and open-source mapping tools."
  },
  {
    "objectID": "data_hacks.html#mexico-and-latam",
    "href": "data_hacks.html#mexico-and-latam",
    "title": "Data Hacks",
    "section": "Mexico and LatAm",
    "text": "Mexico and LatAm\n\nINEGI\nThe Instituto Nacional de Estadística y Geografía (INEGI) is a Mexican public organisation that provides geographical and population data for research and policy-making. INEGI also provides periodic results from various population and economic censuses and nationwide surveys.\nMarco Geoestadístico\nThe MG (Geostatistical Framework) is a product that combines vector information, attribute tables, and catalogues. It illustrates the division of the national territory into successive levels of geostatistical disaggregation. (INEGI).\nTo get the 2020 MG version , we can run the following command in the root repository:\n# Download zip (3.2 Gb)\nwget \"https://www.inegi.org.mx/contenidos/productos/prod_serv/contenidos/espanol/bvinegi/productos/geografia/marcogeo/889463807469/889463807469_s.zip\" -O ./data/raw/marcogeo_2020.zip\n\n# Unzip files\nunzip -o ./data/raw/marcogeo_2020.zip -d ./data/raw/marco_geo_2020\n\nrm ./data/raw/marcogeo_2020.zip\n\n# Loop for unzip entity level data \nfor z in ./data/raw/marco_geo_2020/*.zip; do\n  [ -e \"$z\" ] || continue   \n  # Create the directory\n  dir=\"${z%.zip}\"           \n  mkdir -p \"$dir\"\n  # Unzip and remove \n  unzip -o \"$z\" -d \"$dir\"\n  rm -f \"$z\"\ndone\nUsing r:\n# Parameters \nURL &lt;- \"https://www.inegi.org.mx/contenidos/productos/prod_serv/contenidos/espanol/bvinegi/productos/geografia/marcogeo/889463807469/889463807469_s.zip\"\nZIP_MAIN &lt;- \"./data/raw/marcogeo_2020.zip\"\nOUT_MAIN &lt;- \"./data/raw/marco_geo_2020\"\n\n# ZIP download  (3.2 GB)\nif (!dir.exists(dirname(ZIP_MAIN))) dir.create(dirname(ZIP_MAIN), recursive = TRUE)\ndownload.file(url, destfile = ZIP_MAIN, mode = \"wb\")\n\n# Unzip file\nunzip(ZIP_MAIN, exdir = OUT_MAIN, overwrite = TRUE)\n\n# Delete ZIP\nfile.remove(ZIP_MAIN)\n\n# Unzip entity level ZIP files \nzip_files &lt;- list.files(OUT_MAIN, pattern = \"\\\\.zip$\", full.names = TRUE)\n\nfor (z in zip_files) {\n  dir_out &lt;- sub(\"\\\\.zip$\", \"\", z)\n  dir.create(dir_out, showWarnings=FALSE, recursive=TRUE)\n  unzip(z, exdir=dir_out, overwrite=TRUE)\n  file.remove(z)\n}\nPython Version:\n\n# Required libraries \nimport os\nimport zipfile\nimport urllib.request\nimport glob\nimport shutil\n\n# Parameters \nURL = \"https://www.inegi.org.mx/contenidos/productos/prod_serv/contenidos/espanol/bvinegi/productos/geografia/marcogeo/889463807469/889463807469_s.zip\"\nZIP_MAIN = \"./data/raw/marcogeo_2020.zip\"\nOUT_MAIN = \"./data/raw/marco_geo_2020\"\n\n# ZIP download  (3.2 GB)\nos.makedirs(os.path.dirname(ZIP_MAIN), exist_ok=True)\nprint(f\"Downloading {URL} → {ZIP_MAIN}\")\nurllib.request.urlretrieve(URL, ZIP_MAIN)\n\n# Unzip file\nprint(f\"Unzipping {ZIP_MAIN} → {OUT_MAIN}\")\nos.makedirs(OUT_MAIN, exist_ok=True)\nwith zipfile.ZipFile(ZIP_MAIN, \"r\") as z:\n    z.extractall(OUT_MAIN)\n\n# Delete main ZIP\nos.remove(ZIP_MAIN)\n\n# Unzip entity level ZIPs \nfor zpath in glob.glob(os.path.join(OUT_MAIN, \"*.zip\")):\n    target_dir = os.path.splitext(zpath)[0]\n    os.makedirs(target_dir, exist_ok=True)\n    try:\n        with zipfile.ZipFile(zpath, \"r\") as z:\n            z.extractall(target_dir)\n    except Exception as e:\n        print(f\"Error extracting {zpath}: {e}\")\n    os.remove(zpath)\nCenso de Población y Vivienda 2020\nThis is one of the most comprehensive data source for finding socio-demographic and economical data from mexican population.\nHere are varios ways to automate results downloading from R, python or command line:\nIn r:\n# Parameters \nOUT_DIR &lt;- './data/raw/mex_censo_2020/'\n\n# Create the out directory \ndir.create(OUT_DIR)\n\n# Create the custom PATHS for entity level census data\npaths &lt;- sprintf(\"https://www.inegi.org.mx/contenidos/programas/ccpv/2020/microdatos/ageb_manzana/RESAGEBURB_%02s_2020_csv.zip\"\n                 , 1:32)\n\n# Download entity zip files\nfor(p in paths){\n  filename &lt;- gsub(\"https://www.inegi.org.mx/contenidos/programas/ccpv/2020/microdatos/ageb_manzana/\",\"\",p)\n  download.file(url = p, \n                destfile = paste0(OUT_DIR,filename),\n                mode = \"wb\",\n                quiet = FALSE)\n}\n\n# Unzip entity level files \nfor(f in list.files(OUT_DIR)){\n  dir_out &lt;- gsub(\".zip\",\"\",f)\n  dir.create(paste0(OUT_DIR, dir_out), showWarnings=FALSE, recursive=TRUE)\n  unzip(paste0(OUT_DIR, f), exdir=paste0(OUT_DIR, dir_out), overwrite=TRUE)\n  file.remove(paste0(OUT_DIR, f))\n}\nCommand Line version:\nset -euo pipefail\n\n# Parameters\nOUT_DIR='./data/raw/mex_censo_2020/'\n\n# Create the out directory\nmkdir -p \"$OUT_DIR\"\n\n# Downloadn entity level ZIPs\nfor i in {1..32}; do\n  printf -v num \"%02d\" \"$i\"\n  url=\"https://www.inegi.org.mx/contenidos/programas/ccpv/2020/microdatos/ageb_manzana/RESAGEBURB_${num}_2020_csv.zip\"\n  filename=\"${url:t}\"                      \n  dest=\"${OUT_DIR}${filename}\"\n\n  echo \"Downloading $url -&gt; $dest\"\n  curl -fL --retry 3 --retry-delay 2 -o \"$dest\" \"$url\"\n\n  dir_out=\"${OUT_DIR}${filename%.zip}\"\n  mkdir -p \"$dir_out\"\n  unzip -o \"$dest\" -d \"$dir_out\"\n  rm -f \"$dest\"\ndone\nPython Version:\n\n# Required Libraries\nimport os\nimport urllib.request\nimport zipfile\n\n# Parameters\nOUT_DIR = \"./data/raw/mex_censo_2020/\"\n\n# Create the out directory\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# Download entity level files \n\n# Base name \nbase = \"https://www.inegi.org.mx/contenidos/programas/ccpv/2020/microdatos/ageb_manzana/RESAGEBURB_{:02d}_2020_csv.zip\"\n\nfor i in range(1, 33):\n    url = base.format(i)\n    filename = url.rsplit(\"/\", 1)[1]\n    dest = os.path.join(OUT_DIR, filename)\n\n    # Download file \n    urllib.request.urlretrieve(url, dest)\n\n    # Extract ZIP files \n    dir_out = os.path.join(OUT_DIR, filename[:-4]) \n    os.makedirs(dir_out, exist_ok=True)\n    with zipfile.ZipFile(dest, \"r\") as z:\n        z.extractall(dir_out)\n\n    # Remove \n    os.remove(dest)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geospatial Analytics Lab",
    "section": "",
    "text": "Welcome to my Digital Geospatial Research Lab! The idea behind my personal geospatial and geostatistical analytics lab is to use open-source data and standard mapping tools, as well as applying machine learning algorithms and analytics, to uncover new information about human activity, nature and market dynamics around the globe.\n\n\n\nIsochrone Calculator\nCompute travel-time catchment areas from an origin over a street network.\nPopulation Reach Analysis\nAn analysis of how the population is distributed across urban communities in Mexico, and how much of this population can be covered by a 15 minutes isochrone by selecting strategic points.\n\n\n\n\nSome background notes that support the projects:\nIn the Data Hacks page, we can review some useful scripts and links into public repositories and open data sources related with geo spatial data.\n\nTo learn more about my broader work visit my main site."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Geospatial Analytics Lab",
    "section": "",
    "text": "Isochrone Calculator\nCompute travel-time catchment areas from an origin over a street network.\nPopulation Reach Analysis\nAn analysis of how the population is distributed across urban communities in Mexico, and how much of this population can be covered by a 15 minutes isochrone by selecting strategic points."
  },
  {
    "objectID": "index.html#theory-notes",
    "href": "index.html#theory-notes",
    "title": "Geospatial Analytics Lab",
    "section": "",
    "text": "Some background notes that support the projects:\nIn the Data Hacks page, we can review some useful scripts and links into public repositories and open data sources related with geo spatial data.\n\nTo learn more about my broader work visit my main site."
  },
  {
    "objectID": "isochrones_es.html#preparación-de-los-datos",
    "href": "isochrones_es.html#preparación-de-los-datos",
    "title": "Isochrones calculator",
    "section": "Preparación de los datos",
    "text": "Preparación de los datos\nPara preparar los datos se utilizó el siguiente enfoque: utilizando el Marco Geoestadístico 2020 del INEGI, se filtró el archivo de calles de la Ciudad de México por el municipio correspondiente. A partir de este filtro, se aplicó una autointersección para obtener las esquinas correspondientes a las vías del municipio.\n### Data ---------------------------------------------------------------------\n\n# Lines and streets from the point of interest\nshp_streets &lt;- st_read(paste0(RAW_DATA, SHP_DIRECTORY,SHP_FILE_C)) |&gt;\n  filter(CVE_MUN == '014') |&gt; \n  st_transform(crs = CRS_MX)\n\n# We get the corners from LINESTRING \ncorners_sf &lt;- st_intersection(shp_streets) |&gt;\n  filter(st_geometry_type(geometry) == \"POINT\") |&gt;\n  select(origins, geometry)\ncorners_sf &lt;- corners_sf[!duplicated(st_as_binary(corners_sf$geometry)), ] |&gt;\n  mutate(id_node = row_number())\nDefinimos nuestro punto de partida en la CDMX, como en la siguiente  como punto de partida.\nSe fijará un presupuesto de tiempo de 30 minutos y se asume como velocidad de conducción de bicilceta media de 4 metros por segundo.\n### Execution  -----------------------------------------------------------------\n\n# Starting Point \n# https://maps.app.goo.gl/CnuKBE7yScWgANmp8\nlat &lt;- 19.39798481495679\nlon &lt;- -99.1615400498479\n\n# Maximum duration of trajectories in seconds \nT_segs &lt;- 30*60 \n\nVEL_MPS &lt;- 4 # Average velocity in metter per second\n\nTWT_IND &lt;- TRUE # Indicator if there are waiting times \nTRAFFIC_WT &lt;- 120 # Witing time in seconds \nTWT_PROB &lt;- 0.1 # Probability of waiting, wait for green lights\n\nPOINT_TOLERANCE_M &lt;- 150 # tolerance to find corner from point (mts)\nADJ_TOLERANCE_M &lt;- 3 # node-edge adjacency tolerance (mts)\nADJE_TOLERANCE_M &lt;- 3 # tolerance for edge-vertex adjacency (mts) \n\nDISPLAY &lt;- TRUE # Display map\nECHO &lt;- FALSE # Print simulation status"
  },
  {
    "objectID": "isochrones_es.html#ejecución",
    "href": "isochrones_es.html#ejecución",
    "title": "Isochrones calculator",
    "section": "Ejecución",
    "text": "Ejecución\nEjecutamos las simulación con las parámetros definidos, obteniendo los siguientes resultados:\nisoc &lt;- calculate_isochrone(lat,lon,T_segs,shp_streets,corners_sf\n                         , VEL_MPS\n                         , TWT_IND, TRAFFIC_WT,TWT_PROB\n                         , POINT_TOLERANCE_M, ADJ_TOLERANCE_M, ADJE_TOLERANCE_M\n                         , DISPLAY\n                         , ECHO\n                         , CRS_MX)\n\nprint(isoc$mapa)\n\nst_write(isoc$paths_isochrone,paste0(\"./data/sample/\", \"/iso_paths.geojson\")\n         ,layer = \"iso_paths.geojson\" )\n\nst_write(isoc$hull_isochrone,paste0(\"./data/sample/\", \"/iso_hull.geojson\")\n         ,layer = \"iso_hull.geojson\" )\n\n\n\nMapa Resultante\n\n\nEn el mapa anterior podemos ver en color gris claro, las calles de interés (restricción de movimiento) correspondientes a las Alcaldías Miguel Hidalgo, Benito Juárez y Coyoacán. En negro son los caminos alcanzables contenidos en la isócrona, y en color azul la isócrona en sí. El punto de partida esta en color verde y se tienen como objetivo alcanzar el punto azul (oficina).\n\n\n\nPuntos de origen y destino\n\n\nComo observamos en la pasada imagen el punto azul esta dentro de nuestra isócrona, permitiendonos concluir que en efecto, podemos realizar nuestro recorrido en al menos 30 min. bajo los supuestos de movilidad que se tomaron."
  },
  {
    "objectID": "isochrones.html#data-preparation",
    "href": "isochrones.html#data-preparation",
    "title": "Isochrones calculator",
    "section": "Data preparation",
    "text": "Data preparation\nThe following approach was used to prepare the data: using INEGI’s 2020 Geostatistical Framework, the Mexico City street file was filtered by the corresponding municipality. Based on this filter, a self-intersection was applied to obtain the corners corresponding to the municipality’s roads.\n### Data ---------------------------------------------------------------------\n\n# Lines and streets from the point of interest\nshp_streets &lt;- st_read(paste0(RAW_DATA, SHP_DIRECTORY,SHP_FILE_C)) |&gt;\n  filter(CVE_MUN == '014') |&gt; \n  st_transform(crs = CRS_MX)\n\n# We get the corners from LINESTRING \ncorners_sf &lt;- st_intersection(shp_streets) |&gt;\n  filter(st_geometry_type(geometry) == \"POINT\") |&gt;\n  select(origins, geometry)\ncorners_sf &lt;- corners_sf[!duplicated(st_as_binary(corners_sf$geometry)), ] |&gt;\n  mutate(id_node = row_number())\nWe define our starting point in Mexico City as the following address: Dirección.\nA time budget of 30 minutes will be set, and the average cycling speed will be assumed to be 4 meters per second.\n### Execution  -----------------------------------------------------------------\n\n# Starting Point \n# https://maps.app.goo.gl/CnuKBE7yScWgANmp8\nlat &lt;- 19.39798481495679\nlon &lt;- -99.1615400498479\n\n# Maximum duration of trajectories in seconds \nT_segs &lt;- 30*60 \n\nVEL_MPS &lt;- 4 # Average velocity in metter per second\n\nTWT_IND &lt;- TRUE # Indicator if there are waiting times \nTRAFFIC_WT &lt;- 120 # Witing time in seconds \nTWT_PROB &lt;- 0.1 # Probability of waiting, wait for green lights\n\nPOINT_TOLERANCE_M &lt;- 150 # tolerance to find corner from point (mts)\nADJ_TOLERANCE_M &lt;- 3 # node-edge adjacency tolerance (mts)\nADJE_TOLERANCE_M &lt;- 3 # tolerance for edge-vertex adjacency (mts) \n\nDISPLAY &lt;- TRUE # Display map\nECHO &lt;- FALSE # Print simulation status"
  },
  {
    "objectID": "isochrones.html#execution",
    "href": "isochrones.html#execution",
    "title": "Isochrones calculator",
    "section": "Execution",
    "text": "Execution\nGiven the past parameters, we execute the simulation. Getting the following results:\nisoc &lt;- calculate_isochrone(lat,lon,T_segs,shp_streets,corners_sf\n                         , VEL_MPS\n                         , TWT_IND, TRAFFIC_WT,TWT_PROB\n                         , POINT_TOLERANCE_M, ADJ_TOLERANCE_M, ADJE_TOLERANCE_M\n                         , DISPLAY\n                         , ECHO\n                         , CRS_MX)\n\nprint(isoc$mapa)\n\nst_write(isoc$paths_isochrone,paste0(\"./data/sample/\", \"/iso_paths.geojson\")\n         ,layer = \"iso_paths.geojson\" )\n\nst_write(isoc$hull_isochrone,paste0(\"./data/sample/\", \"/iso_hull.geojson\")\n         ,layer = \"iso_hull.geojson\" )\n\n\n\nResulting Map\n\n\nIn the map above, we can see in light gray the streets of interest (movement restriction) corresponding to the Miguel Hidalgo, Benito Juárez, and Coyoacán municipalities. In black are the reachable roads contained in the isochrone, and in blue is the isochrone itself. The starting point is in green, and the goal is to reach the blue point (office).\n\n\n\nPoints of origin and destination\n\n\nAs we can see in the previous image, the blue point is within our isochrone, allowing us to conclude that we can indeed complete our journey in at least 30 minutes under the mobility assumptions that were made."
  },
  {
    "objectID": "mexico-population-density.html",
    "href": "mexico-population-density.html",
    "title": "Population Density - Mexico",
    "section": "",
    "text": "In this notebook, we explore the task of creating a list of points on the map. Apart from this, we seek to place them in such a way that the number of people within the 15-minute isochrone from each point is maximised for a given transport time.\nProblem Statement:\nConsider the following scenario: you are a retail store entering the Mexican market and developing an expansion plan for Mexico. The C-suite tells you that the strategy is to start by opening ten stores in the country, providing the following guidance:\n\n1.- You must open ten stores in ten different states.\n2.- The objective is to maximise the population within a 15-minute radius of each store.\n3.- You can select any geographical location; there are no other geographical restrictions.\n4.- For a store to be considered part of a state, it must be located within the state, and at least 90% of its isochrone must also be within the state.\n\nPlease note that, for the sake of this experiment, we are ignoring geographical, political, legal and security constraints, which would otherwise be applicable for a more realistic approach.\n\n\nIn this notebook, we explore the task of creating a list of points on the map. Apart from this, we seek to place them in such a way that the number of people within the 15-minute isochrone from each point is maximised for a given transport time.\nFirst the census data:\n### Data ---------------------------------------------------------------------\n\n\n# Censo 2020 nivel manzana \nfiles &lt;- sprintf(\"%s/RESAGEBURB_%02s_2020_csv/RESAGEBURB_%02sCSV20.csv\"\n                , paste0(RAW_DATA,CENSO_FOLDER)\n                , 1:32, 1:32)\n\nfiles_raw &lt;- lapply(files, function(f) {\n  if (file.exists(f)) read.csv(f) else NULL\n})\n\ncenso_df &lt;- do.call(rbind, files_raw[!sapply(files_raw, is.null)]) |&gt;\n  # Filter ouit aggregated total for entity, mun, ageb\n  filter(ENTIDAD !=0, MUN != 0, LOC != 0, AGEB != '0000', MZA != 0)  |&gt;\n  # Select the columns of interest \n  select('ENTIDAD','MUN','LOC','AGEB','MZA', 'POBTOT')  |&gt;\n  # Give format to columns and create index CVEGEO\n  mutate(\n    ENTIDAD = sprintf(\"%02s\", ENTIDAD), \n    MUN = sprintf(\"%03s\", MUN), \n    LOC = sprintf(\"%04s\", LOC), \n    AGEB = sprintf(\"%04s\", AGEB), \n    MZA = sprintf(\"%03s\", MZA),\n    CVEGEO = paste0(ENTIDAD, MUN, LOC, AGEB, MZA)\n  )\nNow we get the shapefiles for each MZA in the country:\n# MZN polygons from the whole country \nfiles &lt;- sprintf(\"%s/%s/conjunto_de_datos/%02sm.shp\"\n                 ,paste0(RAW_DATA,MARCOGEO_FOLDER)\n                 , listDirectory(paste0(RAW_DATA,MARCOGEO_FOLDER)), 1:32)\n\nshapes &lt;- lapply(files, function(f) {\n  if (file.exists(f)) st_read(f, quiet = TRUE) else NULL\n})\n\n# Concat all SHP files and delete null geometries \n\nmzns_shp &lt;- do.call(rbind, shapes[!sapply(shapes, is.null)]) |&gt;\n  st_make_valid()\n\nmzns_shp &lt;- mzns_shp[!is.na(st_geometry(mzns_shp)) & !st_is_empty(mzns_shp), ]\nFinally, we add both in the same table and assign the correspondig Uber’s H3 Cell ( See documentation ). This in order to better aggregate total population by zone regardless of INEGI’s official stratification.\n\n# Clean up  NAs in population variable\ncenso_df$POBTOT &lt;- ifelse(is.na(as.numeric(censo_df$POBTOT)),\n                          0, as.numeric(censo_df$POBTOT))\n\n# Add geometries to each object \ncenso_sf &lt;- censo_df |&gt;\n  left_join(mzns_shp\n            , by = 'CVEGEO') |&gt;\n  st_as_sf(crs = st_crs(mzns_shp)) |&gt;\n  mutate(\n    # Centroid ,st_point_on_surface to make sure is an inner point\n    geometry   = st_point_on_surface(geometry),     \n  ) \n\n\n# Drop Null Geometries \ncenso_sf &lt;- censo_sf[!is.na(st_geometry(censo_sf)) & !st_is_empty(censo_sf), ]\n\n# Add H3 cell corresponding to each point \ncenso_sf &lt;- censo_sf |&gt;\n  mutate(\n    CELL = point_to_cell(st_transform(geometry,4326), res = H3_RESOLUTION), \n  ) |&gt;\n  # Just keep the columns to use in the algorithm \n  select(CVEGEO, ENTIDAD, CELL, POBTOT)\n\n# Aggregated at a cell level\nagg_cell &lt;- censo_sf |&gt;\n  group_by(CELL) |&gt; \n  summarise(\n    POBTOT = sum(POBTOT, na.rm = TRUE),\n    .groups = \"drop\"\n  ) \nWe save the complete sf object as a GeoJSON to do not need to process all data more than once, also save the polygon files of the country states, also save a pre calculated aggregate of population by cell.\n\n\n# Save the data into a processed folder \nst_write(censo_sf,paste0(PROC_DATA, CENSO_GEOJSON)\n         ,layer = CENSO_GEOJSON)\n  \nst_write(agg_cell,paste0(PROC_DATA, CELLS_GEOJSON)\n         ,layer = CELLS_GEOJSON)\nRead the cleaned info\n\n# Read the clean data \ncenso_sf &lt;- st_read(paste0(PROC_DATA, CENSO_GEOJSON))\ncells_sf &lt;- st_read(paste0(PROC_DATA, CELLS_GEOJSON))\n\n# Append cell geometry to aggregate and add entity column \ncells_sf &lt;- cells_sf |&gt; \n  # Assign state to each cell\n  left_join(\n    censo_sf |&gt; st_drop_geometry() |&gt; select(CELL,ENTIDAD) |&gt; distinct(CELL, .keep_all = TRUE)\n            , by = 'CELL') |&gt;\n  # Dropping old geoometry \n  st_drop_geometry() |&gt;    \n  # H3 geometry in WGS84\n  mutate(geometry = cell_to_polygon(CELL)) |&gt;        \n   # H3 uses EPSG:4326\n  st_as_sf(crs = 4326) \n\n# Get x, y coordinates from MZN centroid to filter out efficiently later\ncenso_sf &lt;- censo_sf  |&gt;\n   mutate(\n    coords = st_coordinates(geometry),\n    lon    = coords[,1],\n    lat    = coords[,2]\n  ) |&gt;\n  select(-coords)\n\n# POBTOT TO Numeric\nnum0 &lt;- function(x) replace_na(suppressWarnings(as.numeric(x)), 0)\n\ncenso_sf &lt;- censo_sf |&gt; mutate(POBTOT = num0(POBTOT))\ncells_sf &lt;- cells_sf |&gt; mutate(POBTOT = num0(POBTOT))\nLet’s see how does the population density looks like in a map:\n\n\n\nPopulation density in Mexican City Metropolitan Area\n\n\nAs we can see, most of the population is highly concentrated in urban areas. Another interesting pattern is that neighbouring cells do not necessarily have a high population. That’s why we should examine the most populated cells in more detail.\n\n\n\nTo satisfy the requested business requirements, we can see that, in order to maximise population reach when selecting 10 locations from 10 states, it is sufficient to create a championship by selecting the location with the best population reach in each state, and then selecting the top 10 states, thus satisfying the restrictions and maximising our objective function.\nNow, the following algorithm is centered at a state level, knowing that this will be repeated in each state.\nThe isochrone approximation Given the high cost of computing isochrones, or equivalently, the high cost of using a reliable API, we are going to use a circular buffer approximation based on a 15-minute isochrone from downtown Mexico City (Mexico City being one of the cities with the worst traffic conditions). By doing this, we will underestimate our point selection reach, which is not necessarily a bad thing given that we ultimately want to maximize it.\nParticularly, we are taking as a center the following point in Mexico City to represent the approcximation on the algorithm showed on the following diagram:\n\n\n\nIsochrone approximation via Inner Circle (ISO15 car in blue, ISO15 motorbike in green)\n\n\nepsilon-greedy selection algorithm\nThe algorithm is based on a simple epsilon-greedy heuristic, that is, in each iteration we are looking for maximize the objective function inmediatly over each step regardless of future better selection, giving space for an exploration (random selection). Here the following pseudo-code:\n------------------------------------------------------------\nAlgorithm: State-Level Population Optimization via Isochrones\n------------------------------------------------------------\n\nSet MAX_ITERS = 250\nSet EPS = 0.5\nSet EPS_DECAY = 0.01\nSet MIN_EPS = 0.05\n\nInitialize opt_points = []\nInitialize opt_values = []\nRecord start_time\n\nFor each state 'ent' in {01, 02, ..., 32}:\n    Initialize:\n        cells_visited = []\n        opt_point = NULL\n        opt_value = -Infinity\n        iters = 0\n        eps = EPS\n        values_hist = []\n\n    Create ordered list of cells for this state:\n        cells_list = all cells within ENTIDAD == ent\n                     ordered by descending population (POBTOT)\n                     unique CELL identifiers only\n\n    While iters &lt; MAX_ITERS:\n        Decrease epsilon: eps = max(MIN_EPS, eps - EPS_DECAY)\n\n        Choose exploration vs exploitation:\n            If random_number &lt; eps:\n                current_cell = random sample from cells_list  # Explore\n            Else:\n                current_cell = top cell in cells_list         # Exploit\n\n        Try:\n            Obtain cell centroid for current_cell\n            Extract coordinates (x, y)\n\n            Select census polygons within bounding box:\n                filter censo_sf within (x ± inside_radius, y ± inside_radius)\n                keep relevant columns\n                assign CRS\n\n            Further filter by spatial coverage:\n                keep polygons covered by circular buffer centered at cell_centroid\n\n            Compute current_value:\n                sum of POBTOT within selected polygons\n\n            If current_value &gt; opt_value:\n                opt_point = cell_centroid\n                opt_value = current_value\n\n        Catch any errors silently and continue\n\n        Update tracking variables:\n            Add current_cell to cells_visited\n            Remove visited cells from cells_list\n            Append opt_value to values_hist\n            Increment iters\n\n        Print iteration progress on same line\n\n    End While\n\n    Append opt_point and opt_value to global opt_points and opt_values\n    Record end_time\n    Print completion summary for this state with timing info\n\nEnd For\n\n------------------------------------------------------------\nEnd of Algorithm\n------------------------------------------------------------\nLet´s run the main loop …\n\nMAX_ITERS &lt;- 250 # Max iterations by state \nEPS &lt;- 0.5 # Epsilon\nEPS_DECAY &lt;- 0.01 #   Epsilon decay\nMIN_EPS &lt;- 0.05\n# NOISE &lt;- # Centroid mnoise in metters \n\n# nationwide lists \nopt_points &lt;- c()\nopt_values &lt;- c()\n\nstart &lt;- Sys.time()\n\n\nfor(ent in sprintf(\"%02s\",1:32)){\n\n\n  # state level values\n  cells_visited &lt;- c()\n  opt_point &lt;- NULL\n  opt_value &lt;- -Inf\n  iters &lt;-0 \n  eps &lt;- EPS \n  values_hist &lt;- c()\n  \n  # Generate ordeneate list of cells (by Population)\n  cells_list &lt;- cells_sf |&gt; \n    st_drop_geometry() |&gt; filter(ENTIDAD == ent) |&gt;\n    select(CELL, POBTOT)  |&gt; arrange(desc(POBTOT)) |&gt;\n    distinct() |&gt; pull(CELL) \n  \n  while(iters &lt; MAX_ITERS){\n    \n    # Define if we explore or maximize instantly\n    eps &lt;- max(MIN_EPS, eps-EPS_DECAY)\n    if(runif(1)&lt;eps){ # Explore\n      current_cell &lt;- sample(cells_list,1)\n    } else{ # Maximize \n      current_cell &lt;- cells_list[1]\n    }\n    \n    # Create a buffer for the selected cell and evaluate \n    try({\n      cell_centroid &lt;- cells_sf |&gt;\n    st_transform(st_crs(mzns_shp)) |&gt;\n        filter(ENTIDAD == ent, CELL == current_cell) |&gt; st_centroid() \n    \n    coords &lt;- cell_centroid |&gt; st_coordinates()\n    x &lt;- coords[,1]  \n    y &lt;- coords[,2]  \n    \n    censo_sf_cell_aux &lt;- censo_sf |&gt;\n      filter(lon &gt;= x - inside_radius,lon &lt;= x + inside_radius\n             , lat &gt;= y - inside_radius,lat &lt;= y + inside_radius) |&gt;\n      select(-c(lon, lat))  |&gt;\n      st_set_crs(st_crs(mzns_shp)) \n    \n    censo_sf_cell_aux &lt;- censo_sf_cell_aux |&gt;\n    st_filter(st_buffer(cell_centroid, dist = inside_radius),\n                  .predicate = st_covered_by)\n    \n    \n    current_value &lt;- censo_sf_cell_aux |&gt; st_drop_geometry() |&gt;\n      pull(POBTOT) |&gt; sum()\n    \n    \n    if(current_value&gt;opt_value) {\n      opt_point &lt;- cell_centroid\n      opt_value &lt;- current_value\n      \n    } else{\n      opt_point &lt;- opt_point\n      opt_value &lt;- opt_value\n    }\n    \n    }, silent = TRUE)\n  \n    \n    \n    # Update lists \n    cells_visited &lt;- c(cells_visited,current_cell)\n    cells_list  &lt;- cells_list[!cells_list %in% cells_visited]\n    opt_point &lt;- opt_point\n    opt_value &lt;- opt_value\n    values_hist &lt;- c(values_hist,opt_value)\n    iters &lt;- iters + 1\n    \n    cat(\"\\rIteracion \", iters, \" completada.\")\n    \n  }\n    \n  # Update global values \n  opt_points &lt;- c(opt_points,opt_point)\n  opt_values &lt;- c(opt_values,opt_value)\n  \n  end &lt;- Sys.time()\n  \n  cat(\"\\nEntidad \", ent,\" con optimo \",opt_value, \" completada en \", end - start ,\" (segs).\\n\")\n  \n}\n\nend &lt;- Sys.time()\n\ncat(\"\\nProceso terminado en \", end - start ,\" (segs).\")\nLet’s view the results to define the 10 points to use as new store points. Here the top 10 points where to put our stores with the best population estimates:\n::: {.cell} ::: {.cell-output-display}\n\n\n\nENTIDAD\nPOBTOT\n\n\n\n\n15\n697993\n\n\n9\n689681\n\n\n14\n517050\n\n\n23\n365597\n\n\n24\n362658\n\n\n21\n348812\n\n\n11\n340956\n\n\n19\n340841\n\n\n30\n333821\n\n\n1\n317798\n\n\n\n::: :::\n\n\n\nWe now calculate the real urban population coverage for the 15 minute isochrone based on the points obtained by the algorithm in the past section using the Isochrones from the HERE API for each one of the selected 10 points:\n\n\nCode\n### Map  -----------------------------------------------------------------------\n\nlibrary(leaflet)\nlibrary(sf)\n\n\ncar_iso15 &lt;- st_read(paste0(SAMPLE_DATA,FINAL_ISO_MX_C))\n\n\nReading layer `isochrone_mx_winners_c' from data source \n  `/Users/edgardaniel/Desktop/quant_projects/geospatial-analytics-lab/data/sample/isochrone_mx_winners_c.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 10 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -103.3443 ymin: 18.93494 xmax: -86.83662 ymax: 25.82199\nGeodetic CRS:  WGS 84\n\n\nCode\nmb_iso15 &lt;- st_read(paste0(SAMPLE_DATA,FINAL_ISO_MX_M))\n\n\nReading layer `isochrone_mx_winners_mb' from data source \n  `/Users/edgardaniel/Desktop/quant_projects/geospatial-analytics-lab/data/sample/isochrone_mx_winners_mb.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 10 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -103.3539 ymin: 18.93631 xmax: -86.83079 ymax: 25.82748\nGeodetic CRS:  WGS 84\n\n\nCode\ncells_sf &lt;- st_read(paste0(SAMPLE_DATA,FILE_CENSO_CELLS))\n\n\nReading layer `censo_cells_2020' from data source \n  `/Users/edgardaniel/Desktop/quant_projects/geospatial-analytics-lab/data/sample/censo_cells_2020.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 51861 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -117.1322 ymin: 14.58152 xmax: -86.70538 ymax: 32.72248\nGeodetic CRS:  WGS 84\n\n\nCode\npal &lt;- colorNumeric(\n  palette = c(\"white\", \"darkblue\"),   # use a color vector or palette name\n  domain = cells_sf$POBTOT\n)\n\nleaflet() |&gt;\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  addPolygons(\n    data = cells_sf, \n    color = \"transparent\",\n    weight = 1,\n    fillColor = ~pal(POBTOT),\n    fillOpacity = 0.5,\n    label = ~paste0(\"POBTOT: \", POBTOT),\n  )  |&gt;\n  addPolygons(\n    data = car_iso15, \n    color = \"black\",\n    weight = 1,\n    fillColor = \"lightgreen\",\n    fillOpacity = 0.7,\n  ) |&gt;\n  addPolygons(\n    data = mb_iso15, \n    color = \"blue\",\n    weight = 1,\n    fillColor = \"lightblue\",\n    fillOpacity = 0.5,\n  ) \n\n\n\n\n\n\nAfter evaluating the results over the census data, we concluded that 6.59% of total population reported by 2020 Census where inside one of the ten isochrones selected, and if we compare the covered population at an state level we can observe:\n::: {.cell} ::: {.cell-output-display}\n\n\n\nCVE_MUN\ntotal_pop\nreached_pop\npop_pct\n\n\n\n\n002\n432205\n432123\n100\n\n\n003\n614447\n587653\n96\n\n\n004\n212645\nNA\nNA\n\n\n005\n1173351\n744387\n63\n\n\n006\n404695\n377858\n93\n\n\n007\n1835486\n1551653\n85\n\n\n008\n246428\n1909\n1\n\n\n009\n128710\nNA\nNA\n\n\n010\n759003\n430994\n57\n\n\n011\n385280\n249894\n65\n\n\n012\n685348\n118159\n17\n\n\n013\n429388\n20877\n5\n\n\n014\n434153\n434153\n100\n\n\n015\n545842\n529061\n97\n\n\n016\n414470\n343525\n83\n\n\n017\n443704\n390920\n88\n\n\n\n::: :::\nWe can conclude here that, given the population concentration in small areas, some states, such as 01 (Aguascalientes) and 24 (San Luis Potosí), have high coverage, while others, such as 09 (Mexico City) and 15 (Mexico State), have low coverage given the extent of urban areas across their territories."
  },
  {
    "objectID": "mexico-population-density.html#data-preparation",
    "href": "mexico-population-density.html#data-preparation",
    "title": "Population Density - Mexico",
    "section": "",
    "text": "In this notebook, we explore the task of creating a list of points on the map. Apart from this, we seek to place them in such a way that the number of people within the 15-minute isochrone from each point is maximised for a given transport time.\nFirst the census data:\n### Data ---------------------------------------------------------------------\n\n\n# Censo 2020 nivel manzana \nfiles &lt;- sprintf(\"%s/RESAGEBURB_%02s_2020_csv/RESAGEBURB_%02sCSV20.csv\"\n                , paste0(RAW_DATA,CENSO_FOLDER)\n                , 1:32, 1:32)\n\nfiles_raw &lt;- lapply(files, function(f) {\n  if (file.exists(f)) read.csv(f) else NULL\n})\n\ncenso_df &lt;- do.call(rbind, files_raw[!sapply(files_raw, is.null)]) |&gt;\n  # Filter ouit aggregated total for entity, mun, ageb\n  filter(ENTIDAD !=0, MUN != 0, LOC != 0, AGEB != '0000', MZA != 0)  |&gt;\n  # Select the columns of interest \n  select('ENTIDAD','MUN','LOC','AGEB','MZA', 'POBTOT')  |&gt;\n  # Give format to columns and create index CVEGEO\n  mutate(\n    ENTIDAD = sprintf(\"%02s\", ENTIDAD), \n    MUN = sprintf(\"%03s\", MUN), \n    LOC = sprintf(\"%04s\", LOC), \n    AGEB = sprintf(\"%04s\", AGEB), \n    MZA = sprintf(\"%03s\", MZA),\n    CVEGEO = paste0(ENTIDAD, MUN, LOC, AGEB, MZA)\n  )\nNow we get the shapefiles for each MZA in the country:\n# MZN polygons from the whole country \nfiles &lt;- sprintf(\"%s/%s/conjunto_de_datos/%02sm.shp\"\n                 ,paste0(RAW_DATA,MARCOGEO_FOLDER)\n                 , listDirectory(paste0(RAW_DATA,MARCOGEO_FOLDER)), 1:32)\n\nshapes &lt;- lapply(files, function(f) {\n  if (file.exists(f)) st_read(f, quiet = TRUE) else NULL\n})\n\n# Concat all SHP files and delete null geometries \n\nmzns_shp &lt;- do.call(rbind, shapes[!sapply(shapes, is.null)]) |&gt;\n  st_make_valid()\n\nmzns_shp &lt;- mzns_shp[!is.na(st_geometry(mzns_shp)) & !st_is_empty(mzns_shp), ]\nFinally, we add both in the same table and assign the correspondig Uber’s H3 Cell ( See documentation ). This in order to better aggregate total population by zone regardless of INEGI’s official stratification.\n\n# Clean up  NAs in population variable\ncenso_df$POBTOT &lt;- ifelse(is.na(as.numeric(censo_df$POBTOT)),\n                          0, as.numeric(censo_df$POBTOT))\n\n# Add geometries to each object \ncenso_sf &lt;- censo_df |&gt;\n  left_join(mzns_shp\n            , by = 'CVEGEO') |&gt;\n  st_as_sf(crs = st_crs(mzns_shp)) |&gt;\n  mutate(\n    # Centroid ,st_point_on_surface to make sure is an inner point\n    geometry   = st_point_on_surface(geometry),     \n  ) \n\n\n# Drop Null Geometries \ncenso_sf &lt;- censo_sf[!is.na(st_geometry(censo_sf)) & !st_is_empty(censo_sf), ]\n\n# Add H3 cell corresponding to each point \ncenso_sf &lt;- censo_sf |&gt;\n  mutate(\n    CELL = point_to_cell(st_transform(geometry,4326), res = H3_RESOLUTION), \n  ) |&gt;\n  # Just keep the columns to use in the algorithm \n  select(CVEGEO, ENTIDAD, CELL, POBTOT)\n\n# Aggregated at a cell level\nagg_cell &lt;- censo_sf |&gt;\n  group_by(CELL) |&gt; \n  summarise(\n    POBTOT = sum(POBTOT, na.rm = TRUE),\n    .groups = \"drop\"\n  ) \nWe save the complete sf object as a GeoJSON to do not need to process all data more than once, also save the polygon files of the country states, also save a pre calculated aggregate of population by cell.\n\n\n# Save the data into a processed folder \nst_write(censo_sf,paste0(PROC_DATA, CENSO_GEOJSON)\n         ,layer = CENSO_GEOJSON)\n  \nst_write(agg_cell,paste0(PROC_DATA, CELLS_GEOJSON)\n         ,layer = CELLS_GEOJSON)\nRead the cleaned info\n\n# Read the clean data \ncenso_sf &lt;- st_read(paste0(PROC_DATA, CENSO_GEOJSON))\ncells_sf &lt;- st_read(paste0(PROC_DATA, CELLS_GEOJSON))\n\n# Append cell geometry to aggregate and add entity column \ncells_sf &lt;- cells_sf |&gt; \n  # Assign state to each cell\n  left_join(\n    censo_sf |&gt; st_drop_geometry() |&gt; select(CELL,ENTIDAD) |&gt; distinct(CELL, .keep_all = TRUE)\n            , by = 'CELL') |&gt;\n  # Dropping old geoometry \n  st_drop_geometry() |&gt;    \n  # H3 geometry in WGS84\n  mutate(geometry = cell_to_polygon(CELL)) |&gt;        \n   # H3 uses EPSG:4326\n  st_as_sf(crs = 4326) \n\n# Get x, y coordinates from MZN centroid to filter out efficiently later\ncenso_sf &lt;- censo_sf  |&gt;\n   mutate(\n    coords = st_coordinates(geometry),\n    lon    = coords[,1],\n    lat    = coords[,2]\n  ) |&gt;\n  select(-coords)\n\n# POBTOT TO Numeric\nnum0 &lt;- function(x) replace_na(suppressWarnings(as.numeric(x)), 0)\n\ncenso_sf &lt;- censo_sf |&gt; mutate(POBTOT = num0(POBTOT))\ncells_sf &lt;- cells_sf |&gt; mutate(POBTOT = num0(POBTOT))\nLet’s see how does the population density looks like in a map:\n\n\n\nPopulation density in Mexican City Metropolitan Area\n\n\nAs we can see, most of the population is highly concentrated in urban areas. Another interesting pattern is that neighbouring cells do not necessarily have a high population. That’s why we should examine the most populated cells in more detail."
  },
  {
    "objectID": "mexico-population-density.html#the-algorithm",
    "href": "mexico-population-density.html#the-algorithm",
    "title": "Population Density - Mexico",
    "section": "",
    "text": "To satisfy the requested business requirements, we can see that, in order to maximise population reach when selecting 10 locations from 10 states, it is sufficient to create a championship by selecting the location with the best population reach in each state, and then selecting the top 10 states, thus satisfying the restrictions and maximising our objective function.\nNow, the following algorithm is centered at a state level, knowing that this will be repeated in each state.\nThe isochrone approximation Given the high cost of computing isochrones, or equivalently, the high cost of using a reliable API, we are going to use a circular buffer approximation based on a 15-minute isochrone from downtown Mexico City (Mexico City being one of the cities with the worst traffic conditions). By doing this, we will underestimate our point selection reach, which is not necessarily a bad thing given that we ultimately want to maximize it.\nParticularly, we are taking as a center the following point in Mexico City to represent the approcximation on the algorithm showed on the following diagram:\n\n\n\nIsochrone approximation via Inner Circle (ISO15 car in blue, ISO15 motorbike in green)\n\n\nepsilon-greedy selection algorithm\nThe algorithm is based on a simple epsilon-greedy heuristic, that is, in each iteration we are looking for maximize the objective function inmediatly over each step regardless of future better selection, giving space for an exploration (random selection). Here the following pseudo-code:\n------------------------------------------------------------\nAlgorithm: State-Level Population Optimization via Isochrones\n------------------------------------------------------------\n\nSet MAX_ITERS = 250\nSet EPS = 0.5\nSet EPS_DECAY = 0.01\nSet MIN_EPS = 0.05\n\nInitialize opt_points = []\nInitialize opt_values = []\nRecord start_time\n\nFor each state 'ent' in {01, 02, ..., 32}:\n    Initialize:\n        cells_visited = []\n        opt_point = NULL\n        opt_value = -Infinity\n        iters = 0\n        eps = EPS\n        values_hist = []\n\n    Create ordered list of cells for this state:\n        cells_list = all cells within ENTIDAD == ent\n                     ordered by descending population (POBTOT)\n                     unique CELL identifiers only\n\n    While iters &lt; MAX_ITERS:\n        Decrease epsilon: eps = max(MIN_EPS, eps - EPS_DECAY)\n\n        Choose exploration vs exploitation:\n            If random_number &lt; eps:\n                current_cell = random sample from cells_list  # Explore\n            Else:\n                current_cell = top cell in cells_list         # Exploit\n\n        Try:\n            Obtain cell centroid for current_cell\n            Extract coordinates (x, y)\n\n            Select census polygons within bounding box:\n                filter censo_sf within (x ± inside_radius, y ± inside_radius)\n                keep relevant columns\n                assign CRS\n\n            Further filter by spatial coverage:\n                keep polygons covered by circular buffer centered at cell_centroid\n\n            Compute current_value:\n                sum of POBTOT within selected polygons\n\n            If current_value &gt; opt_value:\n                opt_point = cell_centroid\n                opt_value = current_value\n\n        Catch any errors silently and continue\n\n        Update tracking variables:\n            Add current_cell to cells_visited\n            Remove visited cells from cells_list\n            Append opt_value to values_hist\n            Increment iters\n\n        Print iteration progress on same line\n\n    End While\n\n    Append opt_point and opt_value to global opt_points and opt_values\n    Record end_time\n    Print completion summary for this state with timing info\n\nEnd For\n\n------------------------------------------------------------\nEnd of Algorithm\n------------------------------------------------------------\nLet´s run the main loop …\n\nMAX_ITERS &lt;- 250 # Max iterations by state \nEPS &lt;- 0.5 # Epsilon\nEPS_DECAY &lt;- 0.01 #   Epsilon decay\nMIN_EPS &lt;- 0.05\n# NOISE &lt;- # Centroid mnoise in metters \n\n# nationwide lists \nopt_points &lt;- c()\nopt_values &lt;- c()\n\nstart &lt;- Sys.time()\n\n\nfor(ent in sprintf(\"%02s\",1:32)){\n\n\n  # state level values\n  cells_visited &lt;- c()\n  opt_point &lt;- NULL\n  opt_value &lt;- -Inf\n  iters &lt;-0 \n  eps &lt;- EPS \n  values_hist &lt;- c()\n  \n  # Generate ordeneate list of cells (by Population)\n  cells_list &lt;- cells_sf |&gt; \n    st_drop_geometry() |&gt; filter(ENTIDAD == ent) |&gt;\n    select(CELL, POBTOT)  |&gt; arrange(desc(POBTOT)) |&gt;\n    distinct() |&gt; pull(CELL) \n  \n  while(iters &lt; MAX_ITERS){\n    \n    # Define if we explore or maximize instantly\n    eps &lt;- max(MIN_EPS, eps-EPS_DECAY)\n    if(runif(1)&lt;eps){ # Explore\n      current_cell &lt;- sample(cells_list,1)\n    } else{ # Maximize \n      current_cell &lt;- cells_list[1]\n    }\n    \n    # Create a buffer for the selected cell and evaluate \n    try({\n      cell_centroid &lt;- cells_sf |&gt;\n    st_transform(st_crs(mzns_shp)) |&gt;\n        filter(ENTIDAD == ent, CELL == current_cell) |&gt; st_centroid() \n    \n    coords &lt;- cell_centroid |&gt; st_coordinates()\n    x &lt;- coords[,1]  \n    y &lt;- coords[,2]  \n    \n    censo_sf_cell_aux &lt;- censo_sf |&gt;\n      filter(lon &gt;= x - inside_radius,lon &lt;= x + inside_radius\n             , lat &gt;= y - inside_radius,lat &lt;= y + inside_radius) |&gt;\n      select(-c(lon, lat))  |&gt;\n      st_set_crs(st_crs(mzns_shp)) \n    \n    censo_sf_cell_aux &lt;- censo_sf_cell_aux |&gt;\n    st_filter(st_buffer(cell_centroid, dist = inside_radius),\n                  .predicate = st_covered_by)\n    \n    \n    current_value &lt;- censo_sf_cell_aux |&gt; st_drop_geometry() |&gt;\n      pull(POBTOT) |&gt; sum()\n    \n    \n    if(current_value&gt;opt_value) {\n      opt_point &lt;- cell_centroid\n      opt_value &lt;- current_value\n      \n    } else{\n      opt_point &lt;- opt_point\n      opt_value &lt;- opt_value\n    }\n    \n    }, silent = TRUE)\n  \n    \n    \n    # Update lists \n    cells_visited &lt;- c(cells_visited,current_cell)\n    cells_list  &lt;- cells_list[!cells_list %in% cells_visited]\n    opt_point &lt;- opt_point\n    opt_value &lt;- opt_value\n    values_hist &lt;- c(values_hist,opt_value)\n    iters &lt;- iters + 1\n    \n    cat(\"\\rIteracion \", iters, \" completada.\")\n    \n  }\n    \n  # Update global values \n  opt_points &lt;- c(opt_points,opt_point)\n  opt_values &lt;- c(opt_values,opt_value)\n  \n  end &lt;- Sys.time()\n  \n  cat(\"\\nEntidad \", ent,\" con optimo \",opt_value, \" completada en \", end - start ,\" (segs).\\n\")\n  \n}\n\nend &lt;- Sys.time()\n\ncat(\"\\nProceso terminado en \", end - start ,\" (segs).\")\nLet’s view the results to define the 10 points to use as new store points. Here the top 10 points where to put our stores with the best population estimates:\n::: {.cell} ::: {.cell-output-display}\n\n\n\nENTIDAD\nPOBTOT\n\n\n\n\n15\n697993\n\n\n9\n689681\n\n\n14\n517050\n\n\n23\n365597\n\n\n24\n362658\n\n\n21\n348812\n\n\n11\n340956\n\n\n19\n340841\n\n\n30\n333821\n\n\n1\n317798\n\n\n\n::: :::"
  },
  {
    "objectID": "mexico-population-density.html#national-amalysis",
    "href": "mexico-population-density.html#national-amalysis",
    "title": "Population Density - Mexico",
    "section": "",
    "text": "We now calculate the real urban population coverage for the 15 minute isochrone based on the points obtained by the algorithm in the past section using the Isochrones from the HERE API for each one of the selected 10 points:\n\n\nCode\n### Map  -----------------------------------------------------------------------\n\nlibrary(leaflet)\nlibrary(sf)\n\n\ncar_iso15 &lt;- st_read(paste0(SAMPLE_DATA,FINAL_ISO_MX_C))\n\n\nReading layer `isochrone_mx_winners_c' from data source \n  `/Users/edgardaniel/Desktop/quant_projects/geospatial-analytics-lab/data/sample/isochrone_mx_winners_c.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 10 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -103.3443 ymin: 18.93494 xmax: -86.83662 ymax: 25.82199\nGeodetic CRS:  WGS 84\n\n\nCode\nmb_iso15 &lt;- st_read(paste0(SAMPLE_DATA,FINAL_ISO_MX_M))\n\n\nReading layer `isochrone_mx_winners_mb' from data source \n  `/Users/edgardaniel/Desktop/quant_projects/geospatial-analytics-lab/data/sample/isochrone_mx_winners_mb.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 10 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -103.3539 ymin: 18.93631 xmax: -86.83079 ymax: 25.82748\nGeodetic CRS:  WGS 84\n\n\nCode\ncells_sf &lt;- st_read(paste0(SAMPLE_DATA,FILE_CENSO_CELLS))\n\n\nReading layer `censo_cells_2020' from data source \n  `/Users/edgardaniel/Desktop/quant_projects/geospatial-analytics-lab/data/sample/censo_cells_2020.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 51861 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -117.1322 ymin: 14.58152 xmax: -86.70538 ymax: 32.72248\nGeodetic CRS:  WGS 84\n\n\nCode\npal &lt;- colorNumeric(\n  palette = c(\"white\", \"darkblue\"),   # use a color vector or palette name\n  domain = cells_sf$POBTOT\n)\n\nleaflet() |&gt;\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  addPolygons(\n    data = cells_sf, \n    color = \"transparent\",\n    weight = 1,\n    fillColor = ~pal(POBTOT),\n    fillOpacity = 0.5,\n    label = ~paste0(\"POBTOT: \", POBTOT),\n  )  |&gt;\n  addPolygons(\n    data = car_iso15, \n    color = \"black\",\n    weight = 1,\n    fillColor = \"lightgreen\",\n    fillOpacity = 0.7,\n  ) |&gt;\n  addPolygons(\n    data = mb_iso15, \n    color = \"blue\",\n    weight = 1,\n    fillColor = \"lightblue\",\n    fillOpacity = 0.5,\n  ) \n\n\n\n\n\n\nAfter evaluating the results over the census data, we concluded that 6.59% of total population reported by 2020 Census where inside one of the ten isochrones selected, and if we compare the covered population at an state level we can observe:\n::: {.cell} ::: {.cell-output-display}\n\n\n\nCVE_MUN\ntotal_pop\nreached_pop\npop_pct\n\n\n\n\n002\n432205\n432123\n100\n\n\n003\n614447\n587653\n96\n\n\n004\n212645\nNA\nNA\n\n\n005\n1173351\n744387\n63\n\n\n006\n404695\n377858\n93\n\n\n007\n1835486\n1551653\n85\n\n\n008\n246428\n1909\n1\n\n\n009\n128710\nNA\nNA\n\n\n010\n759003\n430994\n57\n\n\n011\n385280\n249894\n65\n\n\n012\n685348\n118159\n17\n\n\n013\n429388\n20877\n5\n\n\n014\n434153\n434153\n100\n\n\n015\n545842\n529061\n97\n\n\n016\n414470\n343525\n83\n\n\n017\n443704\n390920\n88\n\n\n\n::: :::\nWe can conclude here that, given the population concentration in small areas, some states, such as 01 (Aguascalientes) and 24 (San Luis Potosí), have high coverage, while others, such as 09 (Mexico City) and 15 (Mexico State), have low coverage given the extent of urban areas across their territories."
  },
  {
    "objectID": "mexico-population-density.html#mexico-city-reach",
    "href": "mexico-population-density.html#mexico-city-reach",
    "title": "Population Density - Mexico",
    "section": "",
    "text": "Lets make a small twist to the problem, and thereby the algorithm, to solve a similar problem inside a particular city.\nNow we want to cover the most of population in Mexico City area by choosing 7 storage locations maximizing the amount of people inside a 15 minute isochrone, with the following conditions:\n\n\nOpen seven stores around the city.\nThe objective is to maximise the population within a 15-minute radius of each store.\nYou can select any location within CDMX; there are no geographical restrictions.\nIf two different isochrones intersect, the number of people reached is counted just once.\n\n\nThe algorithm for this part uses the same heuristic logic, employing the circular buffer to approximate the final isochrones and moving from cell to cell until the optimal location for the storage units around the city is found, while penalizing overlapping isochrone areas by not counting overlapping area population. The following is the pseudo code for the algorithm:\n\n------------------------------------------------------------\nAlgorithm: CDMX Population Coverage Optimization\n------------------------------------------------------------\n\n1.  Filter input data to keep only the CDMX cells.\n\n2.  Set parameters:\n        MAX_ITERS     = 300\n        EPS            = 0.5\n        EPS_DECAY      = 0.01\n        MIN_EPS        = 0.05\n        STORAGE_UNITS  = 7\n\n3.  Initialize storage structures:\n        opt_points      ← empty list\n        opt_cells       ← empty list\n        opt_values      ← empty numeric vector\n        isochrones_list ← empty list\n\n4.  Initialize loop variables:\n        cells_visited ← empty vector\n        min_idx       ← NULL\n        min_value     ← -∞\n        iters         ← 1\n        eps           ← EPS\n        values_hist   ← empty vector\n\n5.  Build ordered list of candidate cells:\n        cells_list ← all CDMX cells sorted by descending population (POBTOT)\n                      unique CELL identifiers only.\n\n6.  Begin main optimization loop:\n        WHILE iters &lt; MAX_ITERS:\n\n            a. Decay exploration rate:\n                   eps ← max(MIN_EPS, eps - EPS_DECAY)\n\n            b. Choose exploration vs exploitation:\n                   IF random_number &lt; eps:\n                        current_cell ← random cell from cells_list     # explore\n                   ELSE:\n                        current_cell ← top cell in cells_list           # exploit\n\n            c. TRY (evaluate selected cell):\n                   1.  Obtain cell centroid and transform to match CRS.\n                   2.  Extract centroid coordinates (x, y).\n                   3.  Select census polygons inside bounding box (x ± inside_radius, y ± inside_radius).\n                   4.  Assign CRS and create circular buffer (point_buffer) with radius = inside_radius.\n                   5.  Spatially filter census polygons covered by the buffer.\n                   6.  Compute current_value = sum of POBTOT within buffer.\n\n                   7.  Adjust for overlap with previous buffers:\n                           hit ← TRUE if point_buffer intersects union of existing isochrones.\n                           IF hit:\n                               inter_shape ← intersection area between current buffer and union of existing ones.\n                               adjustment  ← sum of POBTOT within inter_shape.\n                               current_value ← current_value - adjustment\n\n                   8.  Update best storage points:\n                           IF iters &gt; STORAGE_UNITS:\n                               # Replace the weakest stored candidate if improved\n                               IF current_value &gt; min_value:\n                                   Replace entry at min_idx with new centroid, cell, value, and buffer.\n                                   Recompute (min_idx, min_value) = index/value of new minimum opt_value.\n                           ELSE:\n                               # Still filling available storage slots\n                               Append current centroid, cell, value, and buffer to lists.\n                               IF current_value &gt; min_value:\n                                   min_value ← current_value\n                                   min_idx   ← iters\n\n            d. Catch any errors silently and continue.\n\n            e. Update iteration tracking:\n                   Add current_cell to cells_visited.\n                   Remove visited cells from cells_list.\n                   Append sum(opt_values) to values_hist.\n                   iters ← iters + 1\n                   Print iteration progress inline.\n\n7.  End WHILE loop.\n\n------------------------------------------------------------\nEnd of Algorithm\n------------------------------------------------------------\n\nNow, let’s run the past algorithm to get the selected storage units around Mexico City that maximizes the total population inside the 15 minutes isochrones:\n\n# We filter the CDMX data to focus on the area of interest \ncdmx_cells_sf &lt;- cells_sf |&gt; filter(ENTIDAD == '09')\n\n\noptions(warn = -1) # Deactivate Warnings \n\nMAX_ITERS &lt;- 300 # Max iterations \nEPS &lt;- 0.5 # Epsilon\nEPS_DECAY &lt;- 0.01 #   Epsilon decay\nMIN_EPS &lt;- 0.05\nSTORAGE_UNITS &lt;- 7\n\n#  lists \nopt_points &lt;-  list()\nopt_cells  &lt;- list()\nopt_values &lt;- numeric()\nisochrones_list &lt;- list()\n\n\n# Value initiations \ncells_visited &lt;- c()\nmin_idx &lt;- NULL # min density index \nmin_value &lt;- -Inf # min density value\niters &lt;- 1  \neps &lt;- EPS \nvalues_hist &lt;- c()\n\nstart &lt;- Sys.time()  \n  \n# Generate ordeneate list of cells (by Population)\ncells_list &lt;- cdmx_cells_sf |&gt; \n    st_drop_geometry() |&gt;\n    select(CELL, POBTOT)  |&gt; arrange(desc(POBTOT)) |&gt;\n    distinct() |&gt; pull(CELL) \n  \nwhile(iters &lt; MAX_ITERS){\n    \n  # Define if we explore or maximize instantly\n  eps &lt;- max(MIN_EPS, eps-EPS_DECAY)\n  if(runif(1)&lt;eps){ # Explore\n    current_cell &lt;- sample(cells_list,1)\n  } else{ # Maximize \n    current_cell &lt;- cells_list[1]\n  }\n    \n  # Create a buffer for the selected cell and evaluate \n  try({\n    cell_centroid &lt;- cdmx_cells_sf |&gt;\n    st_transform(st_crs(mzns_shp)) |&gt;\n      filter(CELL == current_cell) |&gt; st_centroid() \n    \n    coords &lt;- cell_centroid |&gt; st_coordinates()\n    x &lt;- coords[,1]  \n    y &lt;- coords[,2]  \n    \n    censo_sf_cell_aux &lt;- censo_sf |&gt;\n      filter(lon &gt;= x - inside_radius,lon &lt;= x + inside_radius\n             , lat &gt;= y - inside_radius,lat &lt;= y + inside_radius) |&gt;\n      select(-c(lon, lat))  |&gt;\n      st_set_crs(st_crs(mzns_shp)) \n    \n    point_buffer &lt;- st_buffer(cell_centroid, dist = inside_radius)\n    \n    censo_sf_cell_aux &lt;- censo_sf_cell_aux |&gt;\n    st_filter(point_buffer,\n                  .predicate = st_covered_by)\n    \n    \n    current_value &lt;- censo_sf_cell_aux |&gt; st_drop_geometry() |&gt;\n      pull(POBTOT) |&gt; sum()\n    \n    \n    # We adjust current_value removing overlapped mzna's. \n    hit &lt;- length(isochrones_list) &gt; 0 &&\n    st_intersects(\n      point_buffer,\n      st_union(st_transform(do.call(c, lapply(isochrones_list, st_as_sfc)), st_crs(point_buffer))),\n      sparse = FALSE\n    )[1, 1]\n    \n    if(hit){\n      inter_shape &lt;- if (length(isochrones_list) == 0){\n        st_sfc(st_geometrycollection(), crs = st_crs(point_buffer))\n        } else {     \n        st_intersection(point_buffer,\n      st_union(st_transform(do.call(c, lapply(isochrones_list, st_as_sfc)), crs = st_crs(point_buffer))))\n        }\n\n      adjustment &lt;- censo_sf_cell_aux |&gt;\n                  st_filter(inter_shape,\n                  .predicate = st_covered_by) |&gt; \n        st_drop_geometry() |&gt; pull(POBTOT) |&gt; sum()\n      current_value &lt;- current_value - adjustment\n    } else{\n      current_value &lt;- current_value   \n    }\n    \n    if(iters&gt;STORAGE_UNITS){\n      # If we improve the worst value \n      if(current_value &gt; min_value) {\n      \n      # Values update \n      opt_points[[min_idx]] &lt;- cell_centroid \n      opt_values[min_idx] &lt;- current_value \n      opt_cells[[min_idx]] &lt;- current_cell\n      isochrones_list[[min_idx]] &lt;- point_buffer\n      \n      # Index update \n      # redefine mins\n      min_value &lt;- Inf\n      for (i in seq_along(opt_values)) {\n        val &lt;- opt_values[i]\n        if (val &lt; min_value) {\n          min_idx &lt;- i\n          min_value &lt;- val\n        }\n      }\n      \n      } \n    } else{\n      # If we have not elected yet 5 storage locations we just add them\n      opt_points[[iters]] &lt;- cell_centroid \n      opt_values[iters] &lt;- current_value \n      opt_cells[[iters]] &lt;- current_cell\n      isochrones_list[[iters]] &lt;- point_buffer\n      \n      if(current_value &gt; min_value) {\n        min_value &lt;- current_value\n        min_idx &lt;- iters\n      }\n      \n    }\n    \n    \n    \n    }, silent = TRUE)\n  \n    \n    \n    # Update lists \n    cells_visited &lt;- c(cells_visited,current_cell)\n    cells_list  &lt;- cells_list[!cells_list %in% cells_visited]\n    values_hist &lt;- c(values_hist,sum(opt_values))\n    iters &lt;- iters + 1\n    \n    cat(\"\\rIter \", iters, \" completed.\")\n    \n  }\n    \nend &lt;- Sys.time()\n\ncat(\"\\nLoop ended:  \", end - start ,\" (segs).\")"
  },
  {
    "objectID": "data_hacks.html#isochrones-and-distance-matrix",
    "href": "data_hacks.html#isochrones-and-distance-matrix",
    "title": "Data Hacks",
    "section": "Isochrones and distance matrix",
    "text": "Isochrones and distance matrix\n\nHERE APIs\n(Here)[https://www.here.com/] is a matured, global player in the geo-spatial/location-tech domain, leveraging decades of map content, sensor and fleet data, to enable real-time location intelligence and mobility solutions.\nOne of these solutions is the Isochrone API, which provides information on the n-minute isochrone for a given point, transportation mode and day. Given their years of experience and the maturity of their enterprise, we can safely assume that they are among the most reliable on the market. For final results or precision-critical tasks, this is one of the benchmark solutions.\nTo consult a list of isochrones via latitude and longitude, we can use the following code snippet:\n\n# Needed library\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(osrm)\nlibrary(hereR)\nlibrary(h3jsr)\nlibrary(purrr)\n\n#Pega aquí tu clave real entre comillas\n# set_key(\"key_token\")\n\n\n\n# Time for isochrone in minutes \nTIME_MIN &lt;- 15\n\n# Center point of the isochrone \nPOINT &lt;- data.frame(\n  lng = -99.17296164232874, # Modify your point(s) coordinates \n  lat = 19.410566883421073\n) |&gt;\n  st_as_sf(coords = c(\"lng\", \"lat\"), crs = 4326)\n\nRANGE_TYPE &lt;-  \"time\" # Time for Isochrones \n\nTRANSPORT &lt;- \"car\" # “scooter” for 2 wheelers including motorbikes \n\nTRAVEL_TIME &lt;- \"01/10/2025 13:00:00\" # The moment the journey begins\n\nTIMEZONE &lt;- \"America/Mexico_City\"\n\n\n\n# Call the HERE API\niso_here15 &lt;- isoline(\n  poi = POINT,\n  range = TIME_MIN*60,\n  range_type = RANGE_TYPE,\n  transport_mode = TRANSPORT,\n  datetime = as.POSIXct(TRAVEL_TIME,  \n                        format = \"%d/%m/%Y %H:%M:%S\", \n                        tz = TIMEZONE)\n)\n\n# We save the GEOJSON with the Isochrone \nst_write(iso_here15, paste0(CLEAN_DATA,\"iso_chrone.geojson\"),\n         driver = \"GeoJSON\",\n         delete_dsn = TRUE)"
  },
  {
    "objectID": "mexico-population-density.html#the-modified-algorithm",
    "href": "mexico-population-density.html#the-modified-algorithm",
    "title": "Population Density - Mexico",
    "section": "The modified Algorithm",
    "text": "The modified Algorithm\nThe algorithm for this part uses the same heuristic logic, employing the circular buffer to approximate the final isochrones and moving from cell to cell until the optimal location for the storage units around the city is found, while penalizing overlapping isochrone areas by not counting overlapping area population. The following is the pseudo code for the algorithm:\n------------------------------------------------------------\nAlgorithm: City level Population Optimization via k Isochrones\n------------------------------------------------------------\n\nSet MAX_ITERS = 750\nSet EPS = 0.5\nSet EPS_DECAY = 0.01\nSet MIN_EPS = 0.05\nSet STORAGE_UNITS = 7\n\ninitialize iteration counter iters = 1\ninitialize epsilon = EPS\ninitialize empty lists:\n    opt_points, opt_cells, opt_values\n    isochrones_list, cvegeo_occupied\ninitialize covered_cvegeos = empty set\ninitialize min_idx = null\ninitialize min_value = -infinity\n\nwhile iters &lt; MAX_ITERS:\n\n    # --- EPSILON GREEDY SELECTION ---\n    decrease epsilon by EPS_DECAY but not below MIN_EPS\n    generate random number r in [0,1]\n\n    if r &lt; epsilon:\n        # explore\n        current_cell = random choice from remaining cells_list\n    else:\n        # exploit\n        current_cell = best available cell in cells_list (first position)\n\n    # --- MAIN LOOP (TRY BLOCK) ---\n    try:\n        # compute centroid of current_cell\n        cell_centroid = centroid of cell\n\n        # create circular buffer around centroid\n        point_buffer = buffer(cell_centroid, inside_radius)\n\n        # find census polygons within buffer AND not already used\n        censo_subset = polygons within bounding box of centroid\n        censo_subset = polygons covered by buffer\n        censo_subset = polygons not in covered_cvegeos\n\n        # compute value = total population inside this buffer\n        current_value = sum( population in censo_subset )\n\n        # --- CASE 1: STORAGE ALREADY FULL ---\n        if iters &gt; STORAGE_UNITS:\n\n            # if new location is better than the current worst\n            if current_value &gt; min_value:\n\n                replace worst slot (min_idx) with:\n                    opt_points[min_idx] = cell_centroid\n                    opt_cells[min_idx]  = current_cell\n                    opt_values[min_idx] = current_value\n                    isochrones_list[min_idx] = point_buffer\n                    cvegeo_occupied[min_idx] = set of CVEGEO in censo_subset\n\n                # recompute covered_cvegeos from all stored units\n                covered_cvegeos = union of all cvegeo_occupied[i]\n\n                # recompute worst slot\n                min_value = +infinity\n                for i from 1 to STORAGE_UNITS:\n                    if opt_values[i] &lt; min_value:\n                        min_value = opt_values[i]\n                        min_idx = i\n\n        # --- CASE 2: FILLING INITIAL STORAGE SLOTS ---\n        else:\n\n            store:\n                opt_points[iters] = cell_centroid\n                opt_cells[iters]  = current_cell\n                opt_values[iters] = current_value\n                isochrones_list[iters] = point_buffer\n                cvegeo_occupied[iters] = set of CVEGEO in censo_subset\n\n            add newly occupied CVEGEO to covered_cvegeos\n\n            # update current best (max value)\n            if current_value &gt; min_value:\n                min_value = current_value\n                min_idx = iters\n\n    except:\n        continue\n\n    # --- UPDATE STATE FOR NEXT ITERATION ---\n    add current_cell to cells_visited\n    remove current_cell from cells_list\n    append sum(opt_values) to values_hist\n    iters = iters + 1\n\nend while\n\n------------------------------------------------------------\nEnd of Algorithm\n------------------------------------------------------------\n\nNow, let’s run the past algorithm to get the selected storage units around Mexico City that maximizes the total population inside the 15 minutes isochrones:\n\n# We filter the CDMX data to focus on the area of interest \ncdmx_cells_sf &lt;- cells_sf |&gt; filter(ENTIDAD == '09')\ncdmx_poly &lt;- st_read(paste0(SAMPLE_DATA,SHP_CDMX))\ncenso_sf &lt;-  censo_sf |&gt; st_set_crs(st_crs(mzns_shp))\n\noptions(warn = -1) # Deactivate Warnings \n\nMAX_ITERS &lt;- 750 # Max iterations \nEPS &lt;- 0.5 # Epsilon\nEPS_DECAY &lt;- 0.1 #   Epsilon decay\nMIN_EPS &lt;- 0.05\nSTORAGE_UNITS &lt;- 7\n\n#  lists \nopt_points &lt;-  list()\nopt_cells  &lt;- list()\nopt_values &lt;- numeric()\nisochrones_list &lt;- list()\ncvegeo_occupied &lt;- list()\n\n# Value initiations \ncells_visited &lt;- c()\nmin_idx &lt;- NULL # min density index \nmin_value &lt;- -Inf # min density value\niters &lt;- 1  \neps &lt;- EPS \nvalues_hist &lt;- c()\ncovered_cvegeos &lt;- c()\n\n\n# Get the city frontier \ncity_boundary &lt;- st_union(st_geometry(cdmx_poly))\n# only allow centers at least D metres from the frontier\nD_min &lt;- as.integer(inside_radius*0.3)\n  \n# Generate ordeneate list of cells (by Population)\ncells_list &lt;- cdmx_cells_sf |&gt;\n  mutate(\n    dist_border = as.numeric(st_distance(st_transform(geometry,st_crs(mzns_shp))\n                            , st_boundary(city_boundary)),\n                             by_element = TRUE)\n    ) |&gt; \n    st_drop_geometry() |&gt;\n  filter(dist_border &gt; D_min) |&gt;\n    select(CELL, POBTOT)  |&gt; arrange(desc(POBTOT)) |&gt;\n    distinct() |&gt; pull(CELL) \n\nMAX_ITERS &lt;- min(MAX_ITERS,length(cells_list))\n\nwhile (iters &lt; MAX_ITERS) {\n  \n  # Epsilon-greedy: explore vs exploit\n  eps &lt;- max(MIN_EPS, eps - EPS_DECAY)\n  if (runif(1) &lt; eps) {        # Explore\n    current_cell &lt;- sample(cells_list, 1)\n  } else {                     # Exploit (best remaining)\n    current_cell &lt;- cells_list[1]\n  }\n  \n  # Main Loop\n  try({\n    cell_centroid &lt;- cdmx_cells_sf |&gt;\n      filter(CELL == current_cell) |&gt;\n      slice(1) |&gt;              \n      st_transform(st_crs(mzns_shp)) |&gt;\n      st_centroid()\n    \n    # Circular buffer \n    point_buffer &lt;- st_buffer(cell_centroid, dist = inside_radius)\n    \n    coords &lt;- cell_centroid |&gt; st_coordinates()\n    x &lt;- coords[,1]  \n    y &lt;- coords[,2]  \n    \n    # Census polygons covered by this buffer and not already occupied\n    censo_sf_cell_aux &lt;- censo_sf |&gt;\n      filter(lon &gt;= x - inside_radius,lon &lt;= x + inside_radius , \n              lat &gt;= y - inside_radius,lat &lt;= y + inside_radius , \n              !CVEGEO %in% covered_cvegeos\n             ) |&gt;\n      st_filter(point_buffer$geometry, .predicate = st_covered_by) |&gt; \n      select(-c(lon, lat)) \n\n    \n    # Get value \n    current_value &lt;- censo_sf_cell_aux |&gt;\n      st_drop_geometry() |&gt;\n      pull(POBTOT) |&gt;\n      sum(na.rm = TRUE)\n    \n    # Compite if we have all storages assigned\n    if (iters &gt; STORAGE_UNITS) {\n      # Replace worst if we improved it\n      if (current_value &gt; min_value) {\n        \n        opt_points[[min_idx]] &lt;- cell_centroid\n        opt_values[min_idx] &lt;- current_value\n        opt_cells[[min_idx]] &lt;- current_cell\n        isochrones_list[[min_idx]] &lt;- point_buffer\n        cvegeo_occupied[[min_idx]] &lt;- censo_sf_cell_aux |&gt;\n          st_drop_geometry() |&gt;\n          select(CVEGEO) |&gt;\n          distinct() |&gt;\n          pull(CVEGEO)\n        \n        covered_cvegeos &lt;- c()\n        for(i in 1:STORAGE_UNITS){\n          covered_cvegeos &lt;- c(covered_cvegeos, \n            cvegeo_occupied[[i]]\n          )\n        }\n        \n        # Recompute worst \n        min_value &lt;- Inf\n        for (i in 1:STORAGE_UNITS) {\n          val &lt;- opt_values[[i]]\n          if (val &lt; min_value) {\n            min_idx &lt;- i\n            min_value &lt;- val\n          }\n        }\n      }\n    } else {\n      # Filling first slots\n      opt_points[[iters]] &lt;- cell_centroid\n      opt_values[iters] &lt;- current_value\n      opt_cells[[iters]] &lt;- current_cell\n      isochrones_list[[iters]] &lt;- point_buffer\n      cvegeo_occupied[[iters]] &lt;- censo_sf_cell_aux |&gt;\n        st_drop_geometry() |&gt;\n        select(CVEGEO) |&gt;\n        distinct() |&gt;\n        pull(CVEGEO)\n      \n      covered_cvegeos &lt;- c(covered_cvegeos, \n            cvegeo_occupied[[iters]]\n          )\n      \n      if (current_value &gt; min_value) {\n        min_value &lt;- current_value\n        min_idx &lt;- iters\n      }\n    }\n  }, silent = FALSE)\n  \n  # Update lists and values  \n  cells_visited &lt;- c(cells_visited, current_cell)\n  cells_list &lt;- cells_list[!cells_list %in% cells_visited]\n  values_hist &lt;- c(values_hist, sum(opt_values))\n  iters &lt;- iters + 1\n  \n}"
  },
  {
    "objectID": "mexico-population-density.html#a-15-minutes-city",
    "href": "mexico-population-density.html#a-15-minutes-city",
    "title": "Population Density - Mexico",
    "section": "A 15 minutes city",
    "text": "A 15 minutes city\nNow, let’s see what the algorithm’s results show about the business problem given at the beginning of the section.\nThe selected location with their respective POBTOT approximation via the circular buffer are:\n\n\nRows: 7 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): lng, lat\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nlng\nlat\n\n\n\n\n-99.13293\n19.38745\n\n\n-99.04301\n19.31666\n\n\n-99.14326\n19.33236\n\n\n-99.04204\n19.37103\n\n\n-99.11010\n19.46679\n\n\n-99.22062\n19.35752\n\n\n-99.18120\n19.46918\n\n\n\n\n\nIf we calculate the HERE API isochrones , we can map out the actual coverage for each one of the selected 15 minutes isochrones :\n\n\nReading layer `isochrone_cdmx_winners_mb' from data source \n  `/Users/edgardaniel/Desktop/quant_projects/geospatial-analytics-lab/data/sample/isochrone_cdmx_winners_mb.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 7 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -99.2601 ymin: 19.27139 xmax: -98.97617 ymax: 19.53644\nGeodetic CRS:  WGS 84\n\n\nReading layer `09ent' from data source \n  `/Users/edgardaniel/Desktop/quant_projects/geospatial-analytics-lab/data/sample/09ent.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2776218 ymin: 786788.9 xmax: 2820850 ymax: 846749.5\nProjected CRS: MEXICO_ITRF_2008_LCC\n\n\nReading layer `cleanpop_cells_cdmx' from data source \n  `/Users/edgardaniel/Desktop/quant_projects/geospatial-analytics-lab/data/sample/cells_cdmx.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1096 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -99.34971 ymin: 19.12303 xmax: -98.94209 ymax: 19.58672\nGeodetic CRS:  WGS 84\n\n\nReading layer `cleaniso_centroids_cdmx' from data source \n  `/Users/edgardaniel/Desktop/quant_projects/geospatial-analytics-lab/data/sample/iso_centroids_cdmx.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 7 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -99.22062 ymin: 19.31666 xmax: -99.04204 ymax: 19.46918\nGeodetic CRS:  WGS 84\n\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor"
  },
  {
    "objectID": "mexico-population-reach.html",
    "href": "mexico-population-reach.html",
    "title": "Population Density - Mexico",
    "section": "",
    "text": "In this notebook, we explore the task of creating a list of points on the map. Apart from this, we seek to place them in such a way that the number of people within the 15-minute isochrone from each point is maximised for a given transport time.\nProblem Statement:\nConsider the following scenario: you are a retail store entering the Mexican market and developing an expansion plan for Mexico. The C-suite tells you that the strategy is to start by opening ten stores in the country, providing the following guidance:\n\n1.- You must open ten stores in ten different states.\n2.- The objective is to maximise the population within a 15-minute radius of each store.\n3.- You can select any geographical location; there are no other geographical restrictions.\n4.- For a store to be considered part of a state, it must be located within the state, and at least 90% of its isochrone must also be within the state.\n\nPlease note that, for the sake of this experiment, we are ignoring geographical, political, legal and security constraints, which would otherwise be applicable for a more realistic approach.\n\n\nIn this notebook, we explore the task of creating a list of points on the map. Apart from this, we seek to place them in such a way that the number of people within the 15-minute isochrone from each point is maximised for a given transport time.\nFirst the census data:\n### Data ---------------------------------------------------------------------\n\n\n# Censo 2020 nivel manzana \nfiles &lt;- sprintf(\"%s/RESAGEBURB_%02s_2020_csv/RESAGEBURB_%02sCSV20.csv\"\n                , paste0(RAW_DATA,CENSO_FOLDER)\n                , 1:32, 1:32)\n\nfiles_raw &lt;- lapply(files, function(f) {\n  if (file.exists(f)) read.csv(f) else NULL\n})\n\ncenso_df &lt;- do.call(rbind, files_raw[!sapply(files_raw, is.null)]) |&gt;\n  # Filter ouit aggregated total for entity, mun, ageb\n  filter(ENTIDAD !=0, MUN != 0, LOC != 0, AGEB != '0000', MZA != 0)  |&gt;\n  # Select the columns of interest \n  select('ENTIDAD','MUN','LOC','AGEB','MZA', 'POBTOT')  |&gt;\n  # Give format to columns and create index CVEGEO\n  mutate(\n    ENTIDAD = sprintf(\"%02s\", ENTIDAD), \n    MUN = sprintf(\"%03s\", MUN), \n    LOC = sprintf(\"%04s\", LOC), \n    AGEB = sprintf(\"%04s\", AGEB), \n    MZA = sprintf(\"%03s\", MZA),\n    CVEGEO = paste0(ENTIDAD, MUN, LOC, AGEB, MZA)\n  )\nNow we get the shapefiles for each MZA in the country:\n# MZN polygons from the whole country \nfiles &lt;- sprintf(\"%s/%s/conjunto_de_datos/%02sm.shp\"\n                 ,paste0(RAW_DATA,MARCOGEO_FOLDER)\n                 , listDirectory(paste0(RAW_DATA,MARCOGEO_FOLDER)), 1:32)\n\nshapes &lt;- lapply(files, function(f) {\n  if (file.exists(f)) st_read(f, quiet = TRUE) else NULL\n})\n\n# Concat all SHP files and delete null geometries \n\nmzns_shp &lt;- do.call(rbind, shapes[!sapply(shapes, is.null)]) |&gt;\n  st_make_valid()\n\nmzns_shp &lt;- mzns_shp[!is.na(st_geometry(mzns_shp)) & !st_is_empty(mzns_shp), ]\nFinally, we add both in the same table and assign the correspondig Uber’s H3 Cell ( See documentation ). This in order to better aggregate total population by zone regardless of INEGI’s official stratification.\n\n# Clean up  NAs in population variable\ncenso_df$POBTOT &lt;- ifelse(is.na(as.numeric(censo_df$POBTOT)),\n                          0, as.numeric(censo_df$POBTOT))\n\n# Add geometries to each object \ncenso_sf &lt;- censo_df |&gt;\n  left_join(mzns_shp\n            , by = 'CVEGEO') |&gt;\n  st_as_sf(crs = st_crs(mzns_shp)) |&gt;\n  mutate(\n    # Centroid ,st_point_on_surface to make sure is an inner point\n    geometry   = st_point_on_surface(geometry),     \n  ) \n\n\n# Drop Null Geometries \ncenso_sf &lt;- censo_sf[!is.na(st_geometry(censo_sf)) & !st_is_empty(censo_sf), ]\n\n# Add H3 cell corresponding to each point \ncenso_sf &lt;- censo_sf |&gt;\n  mutate(\n    CELL = point_to_cell(st_transform(geometry,4326), res = H3_RESOLUTION), \n  ) |&gt;\n  # Just keep the columns to use in the algorithm \n  select(CVEGEO, ENTIDAD, CELL, POBTOT)\n\n# Aggregated at a cell level\nagg_cell &lt;- censo_sf |&gt;\n  group_by(CELL) |&gt; \n  summarise(\n    POBTOT = sum(POBTOT, na.rm = TRUE),\n    .groups = \"drop\"\n  ) \nWe save the complete sf object as a GeoJSON to do not need to process all data more than once, also save the polygon files of the country states, also save a pre calculated aggregate of population by cell.\n\n\n# Save the data into a processed folder \nst_write(censo_sf,paste0(PROC_DATA, CENSO_GEOJSON)\n         ,layer = CENSO_GEOJSON)\n  \nst_write(agg_cell,paste0(PROC_DATA, CELLS_GEOJSON)\n         ,layer = CELLS_GEOJSON)\nRead the cleaned info\n\n# Read the clean data \ncenso_sf &lt;- st_read(paste0(PROC_DATA, CENSO_GEOJSON), quiet = TRUE)\ncells_sf &lt;- st_read(paste0(PROC_DATA, CELLS_GEOJSON), quiet = TRUE)\n\n# Append cell geometry to aggregate and add entity column \ncells_sf &lt;- cells_sf |&gt; \n  # Assign state to each cell\n  left_join(\n    censo_sf |&gt; st_drop_geometry() |&gt; select(CELL,ENTIDAD) |&gt; distinct(CELL, .keep_all = TRUE)\n            , by = 'CELL') |&gt;\n  # Dropping old geoometry \n  st_drop_geometry() |&gt;    \n  # H3 geometry in WGS84\n  mutate(geometry = cell_to_polygon(CELL)) |&gt;        \n   # H3 uses EPSG:4326\n  st_as_sf(crs = 4326) \n\n# Get x, y coordinates from MZN centroid to filter out efficiently later\ncenso_sf &lt;- censo_sf  |&gt;\n   mutate(\n    coords = st_coordinates(geometry),\n    lon    = coords[,1],\n    lat    = coords[,2]\n  ) |&gt;\n  select(-coords)\n\n# POBTOT TO Numeric\nnum0 &lt;- function(x) replace_na(suppressWarnings(as.numeric(x)), 0)\n\ncenso_sf &lt;- censo_sf |&gt; mutate(POBTOT = num0(POBTOT))\ncells_sf &lt;- cells_sf |&gt; mutate(POBTOT = num0(POBTOT))\nLet’s see how does the population density looks like in a map:\n\n\n\nPopulation density in Mexican City Metropolitan Area\n\n\nAs we can see, most of the population is highly concentrated in urban areas. Another interesting pattern is that neighbouring cells do not necessarily have a high population. That’s why we should examine the most populated cells in more detail.\n\n\n\nTo satisfy the requested business requirements, we can see that, in order to maximise population reach when selecting 10 locations from 10 states, it is sufficient to create a championship by selecting the location with the best population reach in each state, and then selecting the top 10 states, thus satisfying the restrictions and maximising our objective function.\nNow, the following algorithm is centered at a state level, knowing that this will be repeated in each state.\nThe isochrone approximation Given the high cost of computing isochrones, or equivalently, the high cost of using a reliable API, we are going to use a circular buffer approximation based on a 15-minute isochrone from downtown Mexico City (Mexico City being one of the cities with the worst traffic conditions). By doing this, we will underestimate our point selection reach, which is not necessarily a bad thing given that we ultimately want to maximize it.\nParticularly, we are taking as a center the following point in Mexico City to represent the approcximation on the algorithm showed on the following diagram:\n\n\n\nIsochrone approximation via Inner Circle (ISO15 car in blue, ISO15 motorbike in green)\n\n\nepsilon-greedy selection algorithm\nThe algorithm is based on a simple epsilon-greedy heuristic, that is, in each iteration we are looking for maximize the objective function inmediatly over each step regardless of future better selection, giving space for an exploration (random selection). Here the following pseudo-code:\n------------------------------------------------------------\nAlgorithm: State-Level Population Optimization via Isochrones\n------------------------------------------------------------\n\nSet MAX_ITERS = 250\nSet EPS = 0.5\nSet EPS_DECAY = 0.01\nSet MIN_EPS = 0.05\n\nInitialize opt_points = []\nInitialize opt_values = []\nRecord start_time\n\nFor each state 'ent' in {01, 02, ..., 32}:\n    Initialize:\n        cells_visited = []\n        opt_point = NULL\n        opt_value = -Infinity\n        iters = 0\n        eps = EPS\n        values_hist = []\n\n    Create ordered list of cells for this state:\n        cells_list = all cells within ENTIDAD == ent\n                     ordered by descending population (POBTOT)\n                     unique CELL identifiers only\n\n    While iters &lt; MAX_ITERS:\n        Decrease epsilon: eps = max(MIN_EPS, eps - EPS_DECAY)\n\n        Choose exploration vs exploitation:\n            If random_number &lt; eps:\n                current_cell = random sample from cells_list  # Explore\n            Else:\n                current_cell = top cell in cells_list         # Exploit\n\n        Try:\n            Obtain cell centroid for current_cell\n            Extract coordinates (x, y)\n\n            Select census polygons within bounding box:\n                filter censo_sf within (x ± inside_radius, y ± inside_radius)\n                keep relevant columns\n                assign CRS\n\n            Further filter by spatial coverage:\n                keep polygons covered by circular buffer centered at cell_centroid\n\n            Compute current_value:\n                sum of POBTOT within selected polygons\n\n            If current_value &gt; opt_value:\n                opt_point = cell_centroid\n                opt_value = current_value\n\n        Catch any errors silently and continue\n\n        Update tracking variables:\n            Add current_cell to cells_visited\n            Remove visited cells from cells_list\n            Append opt_value to values_hist\n            Increment iters\n\n        Print iteration progress on same line\n\n    End While\n\n    Append opt_point and opt_value to global opt_points and opt_values\n    Record end_time\n    Print completion summary for this state with timing info\n\nEnd For\n\n------------------------------------------------------------\nEnd of Algorithm\n------------------------------------------------------------\nLet´s run the main loop …\n\nMAX_ITERS &lt;- 250 # Max iterations by state \nEPS &lt;- 0.5 # Epsilon\nEPS_DECAY &lt;- 0.01 #   Epsilon decay\nMIN_EPS &lt;- 0.05\n# NOISE &lt;- # Centroid mnoise in metters \n\n# nationwide lists \nopt_points &lt;- c()\nopt_values &lt;- c()\n\nstart &lt;- Sys.time()\n\n\nfor(ent in sprintf(\"%02s\",1:32)){\n\n\n  # state level values\n  cells_visited &lt;- c()\n  opt_point &lt;- NULL\n  opt_value &lt;- -Inf\n  iters &lt;-0 \n  eps &lt;- EPS \n  values_hist &lt;- c()\n  \n  # Generate ordeneate list of cells (by Population)\n  cells_list &lt;- cells_sf |&gt; \n    st_drop_geometry() |&gt; filter(ENTIDAD == ent) |&gt;\n    select(CELL, POBTOT)  |&gt; arrange(desc(POBTOT)) |&gt;\n    distinct() |&gt; pull(CELL) \n  \n  while(iters &lt; MAX_ITERS){\n    \n    # Define if we explore or maximize instantly\n    eps &lt;- max(MIN_EPS, eps-EPS_DECAY)\n    if(runif(1)&lt;eps){ # Explore\n      current_cell &lt;- sample(cells_list,1)\n    } else{ # Maximize \n      current_cell &lt;- cells_list[1]\n    }\n    \n    # Create a buffer for the selected cell and evaluate \n    try({\n      cell_centroid &lt;- cells_sf |&gt;\n    st_transform(st_crs(mzns_shp)) |&gt;\n        filter(ENTIDAD == ent, CELL == current_cell) |&gt; st_centroid() \n    \n    coords &lt;- cell_centroid |&gt; st_coordinates()\n    x &lt;- coords[,1]  \n    y &lt;- coords[,2]  \n    \n    censo_sf_cell_aux &lt;- censo_sf |&gt;\n      filter(lon &gt;= x - inside_radius,lon &lt;= x + inside_radius\n             , lat &gt;= y - inside_radius,lat &lt;= y + inside_radius) |&gt;\n      select(-c(lon, lat))  |&gt;\n      st_set_crs(st_crs(mzns_shp)) \n    \n    censo_sf_cell_aux &lt;- censo_sf_cell_aux |&gt;\n    st_filter(st_buffer(cell_centroid, dist = inside_radius),\n                  .predicate = st_covered_by)\n    \n    \n    current_value &lt;- censo_sf_cell_aux |&gt; st_drop_geometry() |&gt;\n      pull(POBTOT) |&gt; sum()\n    \n    \n    if(current_value&gt;opt_value) {\n      opt_point &lt;- cell_centroid\n      opt_value &lt;- current_value\n      \n    } else{\n      opt_point &lt;- opt_point\n      opt_value &lt;- opt_value\n    }\n    \n    }, silent = TRUE)\n  \n    \n    \n    # Update lists \n    cells_visited &lt;- c(cells_visited,current_cell)\n    cells_list  &lt;- cells_list[!cells_list %in% cells_visited]\n    opt_point &lt;- opt_point\n    opt_value &lt;- opt_value\n    values_hist &lt;- c(values_hist,opt_value)\n    iters &lt;- iters + 1\n    \n    cat(\"\\rIteracion \", iters, \" completada.\")\n    \n  }\n    \n  # Update global values \n  opt_points &lt;- c(opt_points,opt_point)\n  opt_values &lt;- c(opt_values,opt_value)\n  \n  end &lt;- Sys.time()\n  \n  cat(\"\\nEntidad \", ent,\" con optimo \",opt_value, \" completada en \", end - start ,\" (segs).\\n\")\n  \n}\n\nend &lt;- Sys.time()\n\ncat(\"\\nProceso terminado en \", end - start ,\" (segs).\")\nLet’s view the results to define the 10 points to use as new store points. Here the top 10 points where to put our stores with the best population estimates:\n::: {.cell} ::: {.cell-output-display}\n\n\n\nENTIDAD\nPOBTOT\n\n\n\n\n15\n697993\n\n\n9\n689681\n\n\n14\n517050\n\n\n23\n365597\n\n\n24\n362658\n\n\n21\n348812\n\n\n11\n340956\n\n\n19\n340841\n\n\n30\n333821\n\n\n1\n317798\n\n\n\n::: :::\n\n\n\nWe now calculate the real urban population coverage for the 15 minute isochrone based on the points obtained by the algorithm in the past section using the Isochrones from the HERE API for each one of the selected 10 points:\n\n\nCode\n### Map  -----------------------------------------------------------------------\n\nlibrary(leaflet)\nlibrary(sf)\n\n\ncar_iso15 &lt;- st_read(paste0(SAMPLE_DATA,FINAL_ISO_MX_C), quiet = TRUE)\nmb_iso15 &lt;- st_read(paste0(SAMPLE_DATA,FINAL_ISO_MX_M), quiet = TRUE)\ncells_sf &lt;- st_read(paste0(SAMPLE_DATA,FILE_CENSO_CELLS), quiet = TRUE)\n\n\npal &lt;- colorNumeric(\n  palette = c(\"white\", \"darkblue\"),   # use a color vector or palette name\n  domain = cells_sf$POBTOT\n)\n\nleaflet() |&gt;\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  addPolygons(\n    data = cells_sf, \n    color = \"transparent\",\n    weight = 1,\n    fillColor = ~pal(POBTOT),\n    fillOpacity = 0.5,\n    label = ~paste0(\"POBTOT: \", POBTOT),\n  )  |&gt;\n  addPolygons(\n    data = car_iso15, \n    color = \"black\",\n    weight = 1,\n    fillColor = \"lightgreen\",\n    fillOpacity = 0.7,\n  ) |&gt;\n  addPolygons(\n    data = mb_iso15, \n    color = \"blue\",\n    weight = 1,\n    fillColor = \"lightblue\",\n    fillOpacity = 0.5,\n  ) \n\n\n\n\n\n\nAfter evaluating the results over the census data, we concluded that 6.59% of total population reported by 2020 Census where inside one of the ten isochrones selected, and if we compare the covered population at an state level we can observe:\n::: {.cell} ::: {.cell-output-display}\n\n\n\nCVE_MUN\ntotal_pop\nreached_pop\npop_pct\n\n\n\n\n002\n432205\n432123\n100\n\n\n003\n614447\n587653\n96\n\n\n004\n212645\nNA\nNA\n\n\n005\n1173351\n744387\n63\n\n\n006\n404695\n377858\n93\n\n\n007\n1835486\n1551653\n85\n\n\n008\n246428\n1909\n1\n\n\n009\n128710\nNA\nNA\n\n\n010\n759003\n430994\n57\n\n\n011\n385280\n249894\n65\n\n\n012\n685348\n118159\n17\n\n\n013\n429388\n20877\n5\n\n\n014\n434153\n434153\n100\n\n\n015\n545842\n529061\n97\n\n\n016\n414470\n343525\n83\n\n\n017\n443704\n390920\n88\n\n\n\n::: :::\nWe can conclude here that, given the population concentration in small areas, some states, such as 01 (Aguascalientes) and 24 (San Luis Potosí), have high coverage, while others, such as 09 (Mexico City) and 15 (Mexico State), have low coverage given the extent of urban areas across their territories."
  },
  {
    "objectID": "mexico-population-reach.html#data-preparation",
    "href": "mexico-population-reach.html#data-preparation",
    "title": "Population Density - Mexico",
    "section": "",
    "text": "In this notebook, we explore the task of creating a list of points on the map. Apart from this, we seek to place them in such a way that the number of people within the 15-minute isochrone from each point is maximised for a given transport time.\nFirst the census data:\n### Data ---------------------------------------------------------------------\n\n\n# Censo 2020 nivel manzana \nfiles &lt;- sprintf(\"%s/RESAGEBURB_%02s_2020_csv/RESAGEBURB_%02sCSV20.csv\"\n                , paste0(RAW_DATA,CENSO_FOLDER)\n                , 1:32, 1:32)\n\nfiles_raw &lt;- lapply(files, function(f) {\n  if (file.exists(f)) read.csv(f) else NULL\n})\n\ncenso_df &lt;- do.call(rbind, files_raw[!sapply(files_raw, is.null)]) |&gt;\n  # Filter ouit aggregated total for entity, mun, ageb\n  filter(ENTIDAD !=0, MUN != 0, LOC != 0, AGEB != '0000', MZA != 0)  |&gt;\n  # Select the columns of interest \n  select('ENTIDAD','MUN','LOC','AGEB','MZA', 'POBTOT')  |&gt;\n  # Give format to columns and create index CVEGEO\n  mutate(\n    ENTIDAD = sprintf(\"%02s\", ENTIDAD), \n    MUN = sprintf(\"%03s\", MUN), \n    LOC = sprintf(\"%04s\", LOC), \n    AGEB = sprintf(\"%04s\", AGEB), \n    MZA = sprintf(\"%03s\", MZA),\n    CVEGEO = paste0(ENTIDAD, MUN, LOC, AGEB, MZA)\n  )\nNow we get the shapefiles for each MZA in the country:\n# MZN polygons from the whole country \nfiles &lt;- sprintf(\"%s/%s/conjunto_de_datos/%02sm.shp\"\n                 ,paste0(RAW_DATA,MARCOGEO_FOLDER)\n                 , listDirectory(paste0(RAW_DATA,MARCOGEO_FOLDER)), 1:32)\n\nshapes &lt;- lapply(files, function(f) {\n  if (file.exists(f)) st_read(f, quiet = TRUE) else NULL\n})\n\n# Concat all SHP files and delete null geometries \n\nmzns_shp &lt;- do.call(rbind, shapes[!sapply(shapes, is.null)]) |&gt;\n  st_make_valid()\n\nmzns_shp &lt;- mzns_shp[!is.na(st_geometry(mzns_shp)) & !st_is_empty(mzns_shp), ]\nFinally, we add both in the same table and assign the correspondig Uber’s H3 Cell ( See documentation ). This in order to better aggregate total population by zone regardless of INEGI’s official stratification.\n\n# Clean up  NAs in population variable\ncenso_df$POBTOT &lt;- ifelse(is.na(as.numeric(censo_df$POBTOT)),\n                          0, as.numeric(censo_df$POBTOT))\n\n# Add geometries to each object \ncenso_sf &lt;- censo_df |&gt;\n  left_join(mzns_shp\n            , by = 'CVEGEO') |&gt;\n  st_as_sf(crs = st_crs(mzns_shp)) |&gt;\n  mutate(\n    # Centroid ,st_point_on_surface to make sure is an inner point\n    geometry   = st_point_on_surface(geometry),     \n  ) \n\n\n# Drop Null Geometries \ncenso_sf &lt;- censo_sf[!is.na(st_geometry(censo_sf)) & !st_is_empty(censo_sf), ]\n\n# Add H3 cell corresponding to each point \ncenso_sf &lt;- censo_sf |&gt;\n  mutate(\n    CELL = point_to_cell(st_transform(geometry,4326), res = H3_RESOLUTION), \n  ) |&gt;\n  # Just keep the columns to use in the algorithm \n  select(CVEGEO, ENTIDAD, CELL, POBTOT)\n\n# Aggregated at a cell level\nagg_cell &lt;- censo_sf |&gt;\n  group_by(CELL) |&gt; \n  summarise(\n    POBTOT = sum(POBTOT, na.rm = TRUE),\n    .groups = \"drop\"\n  ) \nWe save the complete sf object as a GeoJSON to do not need to process all data more than once, also save the polygon files of the country states, also save a pre calculated aggregate of population by cell.\n\n\n# Save the data into a processed folder \nst_write(censo_sf,paste0(PROC_DATA, CENSO_GEOJSON)\n         ,layer = CENSO_GEOJSON)\n  \nst_write(agg_cell,paste0(PROC_DATA, CELLS_GEOJSON)\n         ,layer = CELLS_GEOJSON)\nRead the cleaned info\n\n# Read the clean data \ncenso_sf &lt;- st_read(paste0(PROC_DATA, CENSO_GEOJSON), quiet = TRUE)\ncells_sf &lt;- st_read(paste0(PROC_DATA, CELLS_GEOJSON), quiet = TRUE)\n\n# Append cell geometry to aggregate and add entity column \ncells_sf &lt;- cells_sf |&gt; \n  # Assign state to each cell\n  left_join(\n    censo_sf |&gt; st_drop_geometry() |&gt; select(CELL,ENTIDAD) |&gt; distinct(CELL, .keep_all = TRUE)\n            , by = 'CELL') |&gt;\n  # Dropping old geoometry \n  st_drop_geometry() |&gt;    \n  # H3 geometry in WGS84\n  mutate(geometry = cell_to_polygon(CELL)) |&gt;        \n   # H3 uses EPSG:4326\n  st_as_sf(crs = 4326) \n\n# Get x, y coordinates from MZN centroid to filter out efficiently later\ncenso_sf &lt;- censo_sf  |&gt;\n   mutate(\n    coords = st_coordinates(geometry),\n    lon    = coords[,1],\n    lat    = coords[,2]\n  ) |&gt;\n  select(-coords)\n\n# POBTOT TO Numeric\nnum0 &lt;- function(x) replace_na(suppressWarnings(as.numeric(x)), 0)\n\ncenso_sf &lt;- censo_sf |&gt; mutate(POBTOT = num0(POBTOT))\ncells_sf &lt;- cells_sf |&gt; mutate(POBTOT = num0(POBTOT))\nLet’s see how does the population density looks like in a map:\n\n\n\nPopulation density in Mexican City Metropolitan Area\n\n\nAs we can see, most of the population is highly concentrated in urban areas. Another interesting pattern is that neighbouring cells do not necessarily have a high population. That’s why we should examine the most populated cells in more detail."
  },
  {
    "objectID": "mexico-population-reach.html#the-algorithm",
    "href": "mexico-population-reach.html#the-algorithm",
    "title": "Population Density - Mexico",
    "section": "",
    "text": "To satisfy the requested business requirements, we can see that, in order to maximise population reach when selecting 10 locations from 10 states, it is sufficient to create a championship by selecting the location with the best population reach in each state, and then selecting the top 10 states, thus satisfying the restrictions and maximising our objective function.\nNow, the following algorithm is centered at a state level, knowing that this will be repeated in each state.\nThe isochrone approximation Given the high cost of computing isochrones, or equivalently, the high cost of using a reliable API, we are going to use a circular buffer approximation based on a 15-minute isochrone from downtown Mexico City (Mexico City being one of the cities with the worst traffic conditions). By doing this, we will underestimate our point selection reach, which is not necessarily a bad thing given that we ultimately want to maximize it.\nParticularly, we are taking as a center the following point in Mexico City to represent the approcximation on the algorithm showed on the following diagram:\n\n\n\nIsochrone approximation via Inner Circle (ISO15 car in blue, ISO15 motorbike in green)\n\n\nepsilon-greedy selection algorithm\nThe algorithm is based on a simple epsilon-greedy heuristic, that is, in each iteration we are looking for maximize the objective function inmediatly over each step regardless of future better selection, giving space for an exploration (random selection). Here the following pseudo-code:\n------------------------------------------------------------\nAlgorithm: State-Level Population Optimization via Isochrones\n------------------------------------------------------------\n\nSet MAX_ITERS = 250\nSet EPS = 0.5\nSet EPS_DECAY = 0.01\nSet MIN_EPS = 0.05\n\nInitialize opt_points = []\nInitialize opt_values = []\nRecord start_time\n\nFor each state 'ent' in {01, 02, ..., 32}:\n    Initialize:\n        cells_visited = []\n        opt_point = NULL\n        opt_value = -Infinity\n        iters = 0\n        eps = EPS\n        values_hist = []\n\n    Create ordered list of cells for this state:\n        cells_list = all cells within ENTIDAD == ent\n                     ordered by descending population (POBTOT)\n                     unique CELL identifiers only\n\n    While iters &lt; MAX_ITERS:\n        Decrease epsilon: eps = max(MIN_EPS, eps - EPS_DECAY)\n\n        Choose exploration vs exploitation:\n            If random_number &lt; eps:\n                current_cell = random sample from cells_list  # Explore\n            Else:\n                current_cell = top cell in cells_list         # Exploit\n\n        Try:\n            Obtain cell centroid for current_cell\n            Extract coordinates (x, y)\n\n            Select census polygons within bounding box:\n                filter censo_sf within (x ± inside_radius, y ± inside_radius)\n                keep relevant columns\n                assign CRS\n\n            Further filter by spatial coverage:\n                keep polygons covered by circular buffer centered at cell_centroid\n\n            Compute current_value:\n                sum of POBTOT within selected polygons\n\n            If current_value &gt; opt_value:\n                opt_point = cell_centroid\n                opt_value = current_value\n\n        Catch any errors silently and continue\n\n        Update tracking variables:\n            Add current_cell to cells_visited\n            Remove visited cells from cells_list\n            Append opt_value to values_hist\n            Increment iters\n\n        Print iteration progress on same line\n\n    End While\n\n    Append opt_point and opt_value to global opt_points and opt_values\n    Record end_time\n    Print completion summary for this state with timing info\n\nEnd For\n\n------------------------------------------------------------\nEnd of Algorithm\n------------------------------------------------------------\nLet´s run the main loop …\n\nMAX_ITERS &lt;- 250 # Max iterations by state \nEPS &lt;- 0.5 # Epsilon\nEPS_DECAY &lt;- 0.01 #   Epsilon decay\nMIN_EPS &lt;- 0.05\n# NOISE &lt;- # Centroid mnoise in metters \n\n# nationwide lists \nopt_points &lt;- c()\nopt_values &lt;- c()\n\nstart &lt;- Sys.time()\n\n\nfor(ent in sprintf(\"%02s\",1:32)){\n\n\n  # state level values\n  cells_visited &lt;- c()\n  opt_point &lt;- NULL\n  opt_value &lt;- -Inf\n  iters &lt;-0 \n  eps &lt;- EPS \n  values_hist &lt;- c()\n  \n  # Generate ordeneate list of cells (by Population)\n  cells_list &lt;- cells_sf |&gt; \n    st_drop_geometry() |&gt; filter(ENTIDAD == ent) |&gt;\n    select(CELL, POBTOT)  |&gt; arrange(desc(POBTOT)) |&gt;\n    distinct() |&gt; pull(CELL) \n  \n  while(iters &lt; MAX_ITERS){\n    \n    # Define if we explore or maximize instantly\n    eps &lt;- max(MIN_EPS, eps-EPS_DECAY)\n    if(runif(1)&lt;eps){ # Explore\n      current_cell &lt;- sample(cells_list,1)\n    } else{ # Maximize \n      current_cell &lt;- cells_list[1]\n    }\n    \n    # Create a buffer for the selected cell and evaluate \n    try({\n      cell_centroid &lt;- cells_sf |&gt;\n    st_transform(st_crs(mzns_shp)) |&gt;\n        filter(ENTIDAD == ent, CELL == current_cell) |&gt; st_centroid() \n    \n    coords &lt;- cell_centroid |&gt; st_coordinates()\n    x &lt;- coords[,1]  \n    y &lt;- coords[,2]  \n    \n    censo_sf_cell_aux &lt;- censo_sf |&gt;\n      filter(lon &gt;= x - inside_radius,lon &lt;= x + inside_radius\n             , lat &gt;= y - inside_radius,lat &lt;= y + inside_radius) |&gt;\n      select(-c(lon, lat))  |&gt;\n      st_set_crs(st_crs(mzns_shp)) \n    \n    censo_sf_cell_aux &lt;- censo_sf_cell_aux |&gt;\n    st_filter(st_buffer(cell_centroid, dist = inside_radius),\n                  .predicate = st_covered_by)\n    \n    \n    current_value &lt;- censo_sf_cell_aux |&gt; st_drop_geometry() |&gt;\n      pull(POBTOT) |&gt; sum()\n    \n    \n    if(current_value&gt;opt_value) {\n      opt_point &lt;- cell_centroid\n      opt_value &lt;- current_value\n      \n    } else{\n      opt_point &lt;- opt_point\n      opt_value &lt;- opt_value\n    }\n    \n    }, silent = TRUE)\n  \n    \n    \n    # Update lists \n    cells_visited &lt;- c(cells_visited,current_cell)\n    cells_list  &lt;- cells_list[!cells_list %in% cells_visited]\n    opt_point &lt;- opt_point\n    opt_value &lt;- opt_value\n    values_hist &lt;- c(values_hist,opt_value)\n    iters &lt;- iters + 1\n    \n    cat(\"\\rIteracion \", iters, \" completada.\")\n    \n  }\n    \n  # Update global values \n  opt_points &lt;- c(opt_points,opt_point)\n  opt_values &lt;- c(opt_values,opt_value)\n  \n  end &lt;- Sys.time()\n  \n  cat(\"\\nEntidad \", ent,\" con optimo \",opt_value, \" completada en \", end - start ,\" (segs).\\n\")\n  \n}\n\nend &lt;- Sys.time()\n\ncat(\"\\nProceso terminado en \", end - start ,\" (segs).\")\nLet’s view the results to define the 10 points to use as new store points. Here the top 10 points where to put our stores with the best population estimates:\n::: {.cell} ::: {.cell-output-display}\n\n\n\nENTIDAD\nPOBTOT\n\n\n\n\n15\n697993\n\n\n9\n689681\n\n\n14\n517050\n\n\n23\n365597\n\n\n24\n362658\n\n\n21\n348812\n\n\n11\n340956\n\n\n19\n340841\n\n\n30\n333821\n\n\n1\n317798\n\n\n\n::: :::"
  },
  {
    "objectID": "mexico-population-reach.html#national-amalysis",
    "href": "mexico-population-reach.html#national-amalysis",
    "title": "Population Density - Mexico",
    "section": "",
    "text": "We now calculate the real urban population coverage for the 15 minute isochrone based on the points obtained by the algorithm in the past section using the Isochrones from the HERE API for each one of the selected 10 points:\n\n\nCode\n### Map  -----------------------------------------------------------------------\n\nlibrary(leaflet)\nlibrary(sf)\n\n\ncar_iso15 &lt;- st_read(paste0(SAMPLE_DATA,FINAL_ISO_MX_C), quiet = TRUE)\nmb_iso15 &lt;- st_read(paste0(SAMPLE_DATA,FINAL_ISO_MX_M), quiet = TRUE)\ncells_sf &lt;- st_read(paste0(SAMPLE_DATA,FILE_CENSO_CELLS), quiet = TRUE)\n\n\npal &lt;- colorNumeric(\n  palette = c(\"white\", \"darkblue\"),   # use a color vector or palette name\n  domain = cells_sf$POBTOT\n)\n\nleaflet() |&gt;\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  addPolygons(\n    data = cells_sf, \n    color = \"transparent\",\n    weight = 1,\n    fillColor = ~pal(POBTOT),\n    fillOpacity = 0.5,\n    label = ~paste0(\"POBTOT: \", POBTOT),\n  )  |&gt;\n  addPolygons(\n    data = car_iso15, \n    color = \"black\",\n    weight = 1,\n    fillColor = \"lightgreen\",\n    fillOpacity = 0.7,\n  ) |&gt;\n  addPolygons(\n    data = mb_iso15, \n    color = \"blue\",\n    weight = 1,\n    fillColor = \"lightblue\",\n    fillOpacity = 0.5,\n  ) \n\n\n\n\n\n\nAfter evaluating the results over the census data, we concluded that 6.59% of total population reported by 2020 Census where inside one of the ten isochrones selected, and if we compare the covered population at an state level we can observe:\n::: {.cell} ::: {.cell-output-display}\n\n\n\nCVE_MUN\ntotal_pop\nreached_pop\npop_pct\n\n\n\n\n002\n432205\n432123\n100\n\n\n003\n614447\n587653\n96\n\n\n004\n212645\nNA\nNA\n\n\n005\n1173351\n744387\n63\n\n\n006\n404695\n377858\n93\n\n\n007\n1835486\n1551653\n85\n\n\n008\n246428\n1909\n1\n\n\n009\n128710\nNA\nNA\n\n\n010\n759003\n430994\n57\n\n\n011\n385280\n249894\n65\n\n\n012\n685348\n118159\n17\n\n\n013\n429388\n20877\n5\n\n\n014\n434153\n434153\n100\n\n\n015\n545842\n529061\n97\n\n\n016\n414470\n343525\n83\n\n\n017\n443704\n390920\n88\n\n\n\n::: :::\nWe can conclude here that, given the population concentration in small areas, some states, such as 01 (Aguascalientes) and 24 (San Luis Potosí), have high coverage, while others, such as 09 (Mexico City) and 15 (Mexico State), have low coverage given the extent of urban areas across their territories."
  },
  {
    "objectID": "mexico-population-reach.html#the-modified-algorithm",
    "href": "mexico-population-reach.html#the-modified-algorithm",
    "title": "Population Density - Mexico",
    "section": "The modified Algorithm",
    "text": "The modified Algorithm\nThe algorithm for this part uses the same heuristic logic, employing the circular buffer to approximate the final isochrones and moving from cell to cell until the optimal location for the storage units around the city is found, while penalizing overlapping isochrone areas by not counting overlapping area population. The following is the pseudo code for the algorithm:\n------------------------------------------------------------\nAlgorithm: City level Population Optimization via k Isochrones\n------------------------------------------------------------\n\nSet MAX_ITERS = 750\nSet EPS = 0.5\nSet EPS_DECAY = 0.01\nSet MIN_EPS = 0.05\nSet STORAGE_UNITS = 7\n\ninitialize iteration counter iters = 1\ninitialize epsilon = EPS\ninitialize empty lists:\n    opt_points, opt_cells, opt_values\n    isochrones_list, cvegeo_occupied\ninitialize covered_cvegeos = empty set\ninitialize min_idx = null\ninitialize min_value = -infinity\n\nwhile iters &lt; MAX_ITERS:\n\n    # --- EPSILON GREEDY SELECTION ---\n    decrease epsilon by EPS_DECAY but not below MIN_EPS\n    generate random number r in [0,1]\n\n    if r &lt; epsilon:\n        # explore\n        current_cell = random choice from remaining cells_list\n    else:\n        # exploit\n        current_cell = best available cell in cells_list (first position)\n\n    # --- MAIN LOOP (TRY BLOCK) ---\n    try:\n        # compute centroid of current_cell\n        cell_centroid = centroid of cell\n\n        # create circular buffer around centroid\n        point_buffer = buffer(cell_centroid, inside_radius)\n\n        # find census polygons within buffer AND not already used\n        censo_subset = polygons within bounding box of centroid\n        censo_subset = polygons covered by buffer\n        censo_subset = polygons not in covered_cvegeos\n\n        # compute value = total population inside this buffer\n        current_value = sum( population in censo_subset )\n\n        # --- CASE 1: STORAGE ALREADY FULL ---\n        if iters &gt; STORAGE_UNITS:\n\n            # if new location is better than the current worst\n            if current_value &gt; min_value:\n\n                replace worst slot (min_idx) with:\n                    opt_points[min_idx] = cell_centroid\n                    opt_cells[min_idx]  = current_cell\n                    opt_values[min_idx] = current_value\n                    isochrones_list[min_idx] = point_buffer\n                    cvegeo_occupied[min_idx] = set of CVEGEO in censo_subset\n\n                # recompute covered_cvegeos from all stored units\n                covered_cvegeos = union of all cvegeo_occupied[i]\n\n                # recompute worst slot\n                min_value = +infinity\n                for i from 1 to STORAGE_UNITS:\n                    if opt_values[i] &lt; min_value:\n                        min_value = opt_values[i]\n                        min_idx = i\n\n        # --- CASE 2: FILLING INITIAL STORAGE SLOTS ---\n        else:\n\n            store:\n                opt_points[iters] = cell_centroid\n                opt_cells[iters]  = current_cell\n                opt_values[iters] = current_value\n                isochrones_list[iters] = point_buffer\n                cvegeo_occupied[iters] = set of CVEGEO in censo_subset\n\n            add newly occupied CVEGEO to covered_cvegeos\n\n            # update current best (max value)\n            if current_value &gt; min_value:\n                min_value = current_value\n                min_idx = iters\n\n    except:\n        continue\n\n    # --- UPDATE STATE FOR NEXT ITERATION ---\n    add current_cell to cells_visited\n    remove current_cell from cells_list\n    append sum(opt_values) to values_hist\n    iters = iters + 1\n\nend while\n\n------------------------------------------------------------\nEnd of Algorithm\n------------------------------------------------------------\n\nNow, let’s run the past algorithm to get the selected storage units around Mexico City that maximizes the total population inside the 15 minutes isochrones:\n\n# We filter the CDMX data to focus on the area of interest \ncdmx_cells_sf &lt;- cells_sf |&gt; filter(ENTIDAD == '09')\ncdmx_poly &lt;- st_read(paste0(SAMPLE_DATA,SHP_CDMX), quiet = TRUE)\ncenso_sf &lt;-  censo_sf |&gt; st_set_crs(st_crs(mzns_shp))\n\noptions(warn = -1) # Deactivate Warnings \n\nMAX_ITERS &lt;- 750 # Max iterations \nEPS &lt;- 0.5 # Epsilon\nEPS_DECAY &lt;- 0.1 #   Epsilon decay\nMIN_EPS &lt;- 0.05\nSTORAGE_UNITS &lt;- 7\n\n#  lists \nopt_points &lt;-  list()\nopt_cells  &lt;- list()\nopt_values &lt;- numeric()\nisochrones_list &lt;- list()\ncvegeo_occupied &lt;- list()\n\n# Value initiations \ncells_visited &lt;- c()\nmin_idx &lt;- NULL # min density index \nmin_value &lt;- -Inf # min density value\niters &lt;- 1  \neps &lt;- EPS \nvalues_hist &lt;- c()\ncovered_cvegeos &lt;- c()\n\n\n# Get the city frontier \ncity_boundary &lt;- st_union(st_geometry(cdmx_poly))\n# only allow centers at least D metres from the frontier\nD_min &lt;- as.integer(inside_radius*0.3)\n  \n# Generate ordeneate list of cells (by Population)\ncells_list &lt;- cdmx_cells_sf |&gt;\n  mutate(\n    dist_border = as.numeric(st_distance(st_transform(geometry,st_crs(mzns_shp))\n                            , st_boundary(city_boundary)),\n                             by_element = TRUE)\n    ) |&gt; \n    st_drop_geometry() |&gt;\n  filter(dist_border &gt; D_min) |&gt;\n    select(CELL, POBTOT)  |&gt; arrange(desc(POBTOT)) |&gt;\n    distinct() |&gt; pull(CELL) \n\nMAX_ITERS &lt;- min(MAX_ITERS,length(cells_list))\n\nwhile (iters &lt; MAX_ITERS) {\n  \n  # Epsilon-greedy: explore vs exploit\n  eps &lt;- max(MIN_EPS, eps - EPS_DECAY)\n  if (runif(1) &lt; eps) {        # Explore\n    current_cell &lt;- sample(cells_list, 1)\n  } else {                     # Exploit (best remaining)\n    current_cell &lt;- cells_list[1]\n  }\n  \n  # Main Loop\n  try({\n    cell_centroid &lt;- cdmx_cells_sf |&gt;\n      filter(CELL == current_cell) |&gt;\n      slice(1) |&gt;              \n      st_transform(st_crs(mzns_shp)) |&gt;\n      st_centroid()\n    \n    # Circular buffer \n    point_buffer &lt;- st_buffer(cell_centroid, dist = inside_radius)\n    \n    coords &lt;- cell_centroid |&gt; st_coordinates()\n    x &lt;- coords[,1]  \n    y &lt;- coords[,2]  \n    \n    # Census polygons covered by this buffer and not already occupied\n    censo_sf_cell_aux &lt;- censo_sf |&gt;\n      filter(lon &gt;= x - inside_radius,lon &lt;= x + inside_radius , \n              lat &gt;= y - inside_radius,lat &lt;= y + inside_radius , \n              !CVEGEO %in% covered_cvegeos\n             ) |&gt;\n      st_filter(point_buffer$geometry, .predicate = st_covered_by) |&gt; \n      select(-c(lon, lat)) \n\n    \n    # Get value \n    current_value &lt;- censo_sf_cell_aux |&gt;\n      st_drop_geometry() |&gt;\n      pull(POBTOT) |&gt;\n      sum(na.rm = TRUE)\n    \n    # Compite if we have all storages assigned\n    if (iters &gt; STORAGE_UNITS) {\n      # Replace worst if we improved it\n      if (current_value &gt; min_value) {\n        \n        opt_points[[min_idx]] &lt;- cell_centroid\n        opt_values[min_idx] &lt;- current_value\n        opt_cells[[min_idx]] &lt;- current_cell\n        isochrones_list[[min_idx]] &lt;- point_buffer\n        cvegeo_occupied[[min_idx]] &lt;- censo_sf_cell_aux |&gt;\n          st_drop_geometry() |&gt;\n          select(CVEGEO) |&gt;\n          distinct() |&gt;\n          pull(CVEGEO)\n        \n        covered_cvegeos &lt;- c()\n        for(i in 1:STORAGE_UNITS){\n          covered_cvegeos &lt;- c(covered_cvegeos, \n            cvegeo_occupied[[i]]\n          )\n        }\n        \n        # Recompute worst \n        min_value &lt;- Inf\n        for (i in 1:STORAGE_UNITS) {\n          val &lt;- opt_values[[i]]\n          if (val &lt; min_value) {\n            min_idx &lt;- i\n            min_value &lt;- val\n          }\n        }\n      }\n    } else {\n      # Filling first slots\n      opt_points[[iters]] &lt;- cell_centroid\n      opt_values[iters] &lt;- current_value\n      opt_cells[[iters]] &lt;- current_cell\n      isochrones_list[[iters]] &lt;- point_buffer\n      cvegeo_occupied[[iters]] &lt;- censo_sf_cell_aux |&gt;\n        st_drop_geometry() |&gt;\n        select(CVEGEO) |&gt;\n        distinct() |&gt;\n        pull(CVEGEO)\n      \n      covered_cvegeos &lt;- c(covered_cvegeos, \n            cvegeo_occupied[[iters]]\n          )\n      \n      if (current_value &gt; min_value) {\n        min_value &lt;- current_value\n        min_idx &lt;- iters\n      }\n    }\n  }, silent = FALSE)\n  \n  # Update lists and values  \n  cells_visited &lt;- c(cells_visited, current_cell)\n  cells_list &lt;- cells_list[!cells_list %in% cells_visited]\n  values_hist &lt;- c(values_hist, sum(opt_values))\n  iters &lt;- iters + 1\n  \n}"
  },
  {
    "objectID": "mexico-population-reach.html#a-15-minutes-city",
    "href": "mexico-population-reach.html#a-15-minutes-city",
    "title": "Population Density - Mexico",
    "section": "A 15 minutes city",
    "text": "A 15 minutes city\nNow, let’s see what the algorithm’s results show about the business problem given at the beginning of the section.\nThe selected location with their respective POBTOT approximation via the circular buffer are:\n\n\nRows: 7 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): lng, lat\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nlng\nlat\n\n\n\n\n-99.13293\n19.38745\n\n\n-99.04301\n19.31666\n\n\n-99.14326\n19.33236\n\n\n-99.04204\n19.37103\n\n\n-99.11010\n19.46679\n\n\n-99.22062\n19.35752\n\n\n-99.18120\n19.46918\n\n\n\n\n\nIf we calculate the HERE API isochrones , we can map out the actual coverage for each one of the selected 15 minutes isochrones :\n\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\n\n\n\n\nOverall, we can conclude that 67.94% of CDMX’s population can be reached within 15 minutes by using only seven strategic points across the city. This opens the door to many solutions in urban mobility, retail commerce, healthcare, and public policy.\nAs we can see from the map, the most populated area is in the northern part of the city. This is because the southern part of the city has forest and lake areas, which is why the population is concentrated in a few municipalities. We can take advantage of this situation by placing strategic points to ensure full coverage. The following table shows the coverage percentage by municipality.\n\n\n\nPopulation coverage (%) by municipallity."
  }
]